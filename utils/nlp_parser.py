"""
è‡ªç„¶è¨€èªå‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
ãƒ¡ãƒ¢ãƒªãƒ¼æ¤œç´¢ã®æŸ”è»Ÿæ€§æ©Ÿèƒ½ã‚’ã‚¢ãƒ©ãƒ¼ãƒ è¨­å®šãƒ»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã«é©ç”¨
"""
import re
import datetime
import pytz
from typing import Optional, Dict, List, Tuple
import logging

logger = logging.getLogger(__name__)

class FlexibleTextParser:
    """æŸ”è»Ÿãªãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def extract_keywords(self, text: str) -> List[str]:
        """
        ãƒ¡ãƒ¢ãƒªãƒ¼æ¤œç´¢ã§å®Ÿè£…ã•ã‚ŒãŸæŸ”è»Ÿãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæ©Ÿèƒ½
        ã€ŒãŠå°»ã®ã“ã¨ã‚’æ•™ãˆã¦ã€â†’ã€ŒãŠå°»ã€ã‚’æŠ½å‡º
        """
        search_keywords = []
        
        # è³ªå•å½¢å¼ã®å ´åˆã€åè©ã‚’æŠ½å‡º
        if any(word in text for word in ["æ•™ãˆã¦", "è¦šãˆã¦ã‚‹", "çŸ¥ã£ã¦ã‚‹", "ã«ã¤ã„ã¦", "ã®ã“ã¨"]):
            words = text
            for remove_word in ["æ•™ãˆã¦", "è¦šãˆã¦ã‚‹", "çŸ¥ã£ã¦ã‚‹", "ï¼Ÿ", "?", "ã®", "ã“ã¨", "ã«ã¤ã„ã¦"]:
                words = words.replace(remove_word, "")
            words = words.strip()
            if words:
                search_keywords.append(words)
        
        # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚è¿½åŠ 
        search_keywords.append(text)
        
        self.logger.info(f"ğŸ” [KEYWORD_EXTRACTION] Extracted keywords from '{text}': {search_keywords}")
        return search_keywords
    
    def _normalize_japanese_text(self, text: str) -> List[str]:
        """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ï¼ˆã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—å¤‰æ›ï¼‰"""
        import unicodedata
        
        normalized_variants = [text.lower()]
        
        # ã²ã‚‰ãŒãªâ†’ã‚«ã‚¿ã‚«ãƒŠå¤‰æ›
        hiragana_to_katakana = ""
        for char in text:
            if 'ã²' <= char <= 'ã‚–':  # ã²ã‚‰ãŒãªç¯„å›²
                hiragana_to_katakana += chr(ord(char) + 0x60)
            else:
                hiragana_to_katakana += char
        if hiragana_to_katakana != text:
            normalized_variants.append(hiragana_to_katakana.lower())
        
        # ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãªå¤‰æ›
        katakana_to_hiragana = ""
        for char in text:
            if 'ã‚¢' <= char <= 'ãƒ¶':  # ã‚«ã‚¿ã‚«ãƒŠç¯„å›²
                katakana_to_hiragana += chr(ord(char) - 0x60)
            else:
                katakana_to_hiragana += char
        if katakana_to_hiragana != text:
            normalized_variants.append(katakana_to_hiragana.lower())
        
        # å…¨è§’â†’åŠè§’å¤‰æ›
        half_width = unicodedata.normalize('NFKC', text).lower()
        if half_width != text.lower():
            normalized_variants.append(half_width)
        
        # AIè§£æã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€åŸºæœ¬çš„ãªæ­£è¦åŒ–ã®ã¿å®Ÿè¡Œ
        # è©³ç´°ãªèª­ã¿æ–¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯AIã«ä»»ã›ã‚‹
        
        return list(set(normalized_variants))  # é‡è¤‡é™¤å»
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """æ–‡å­—åˆ—ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆæ—¥æœ¬èªå¯¾å¿œæ”¹è‰¯ç‰ˆï¼‰"""
        if not str1 or not str2:
            return 0.0
        
        # æ­£è¦åŒ–ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆ
        str1_variants = self._normalize_japanese_text(str1)
        str2_variants = self._normalize_japanese_text(str2)
        
        max_similarity = 0.0
        
        # å…¨çµ„ã¿åˆã‚ã›ã§æœ€é«˜é¡ä¼¼åº¦ã‚’è¨ˆç®—
        for v1 in str1_variants:
            for v2 in str2_variants:
                # å®Œå…¨ä¸€è‡´
                if v1 == v2:
                    return 1.0
                
                # éƒ¨åˆ†ä¸€è‡´ï¼ˆå«ã¾ã‚Œã‚‹é–¢ä¿‚ï¼‰
                if v1 in v2 or v2 in v1:
                    max_similarity = max(max_similarity, 0.8)
                    continue
                
                # å…±é€šæ–‡å­—æ•°ã‚’è¨ˆç®—
                len1, len2 = len(v1), len(v2)
                common = 0
                v2_chars = list(v2)
                
                for char in v1:
                    if char in v2_chars:
                        v2_chars.remove(char)  # é‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã‚’é˜²ã
                        common += 1
                
                # ã‚¸ãƒ£ãƒƒã‚«ãƒ¼ãƒ‰ä¿‚æ•°çš„ãªè¨ˆç®—
                union_size = len1 + len2 - common
                if union_size > 0:
                    similarity = common / union_size
                    max_similarity = max(max_similarity, similarity)
        
        return max_similarity

class AlarmTextParser(FlexibleTextParser):
    """ã‚¢ãƒ©ãƒ¼ãƒ è¨­å®šç”¨ã®è‡ªç„¶è¨€èªå‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def parse_alarm_text(self, text: str, timezone: str = "Asia/Tokyo") -> Optional[Dict]:
        """
        è‡ªç„¶è¨€èªã‹ã‚‰ã‚¢ãƒ©ãƒ¼ãƒ è¨­å®šã‚’è§£æ
        ã€Œæ˜æ—¥ã®æœ7æ™‚ã«ãŠè–¬ã‚’é£²ã‚€ã“ã¨ã‚’æ€ã„å‡ºã•ã›ã¦ã€â†’ {date: "2025-09-21", time: "07:00", message: "ãŠè–¬ã‚’é£²ã‚€"}
        """
        try:
            self.logger.info(f"ğŸ” [ALARM_PARSE] Parsing alarm text: '{text}'")
            
            # æ—¥ä»˜ãƒ»æ™‚åˆ»ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            result = {}
            
            # æ™‚åˆ»ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
            time_patterns = [
                (r'(\d{1,2})æ™‚(\d{1,2})åˆ†', lambda m: f"{int(m.group(1)):02d}:{int(m.group(2)):02d}"),
                (r'(\d{1,2})æ™‚åŠ', lambda m: f"{int(m.group(1)):02d}:30"),
                (r'(\d{1,2})æ™‚', lambda m: f"{int(m.group(1)):02d}:00"),
                (r'åˆå‰(\d{1,2})æ™‚', lambda m: f"{int(m.group(1)):02d}:00"),
                (r'åˆå¾Œ(\d{1,2})æ™‚', lambda m: f"{int(m.group(1)) + 12 if int(m.group(1)) < 12 else int(m.group(1)):02d}:00"),
                (r'æœ(\d{1,2})æ™‚', lambda m: f"{int(m.group(1)):02d}:00"),
                (r'å¤œ(\d{1,2})æ™‚', lambda m: f"{int(m.group(1)) + 12 if int(m.group(1)) < 12 else int(m.group(1)):02d}:00"),
            ]
            
            # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
            date_patterns = [
                (r'ä»Šæ—¥', lambda: datetime.datetime.now(pytz.timezone(timezone)).date()),
                (r'æ˜æ—¥', lambda: (datetime.datetime.now(pytz.timezone(timezone)) + datetime.timedelta(days=1)).date()),
                (r'æ˜å¾Œæ—¥', lambda: (datetime.datetime.now(pytz.timezone(timezone)) + datetime.timedelta(days=2)).date()),
                (r'(\d{1,2})æ—¥', lambda m: self._get_next_date_with_day(int(m.group(1)), timezone)),
            ]
            
            # æ™‚åˆ»ã‚’æŠ½å‡º
            time_found = None
            for pattern, converter in time_patterns:
                match = re.search(pattern, text)
                if match:
                    time_found = converter(match)
                    break
            
            # æ—¥ä»˜ã‚’æŠ½å‡º
            date_found = None
            for pattern, converter in date_patterns:
                if re.search(pattern, text):
                    date_found = converter()
                    break
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
            if not date_found:
                date_found = datetime.datetime.now(pytz.timezone(timezone)).date()
            
            if not time_found:
                # æ™‚åˆ»ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç¾åœ¨æ™‚åˆ»ã‹ã‚‰1æ™‚é–“å¾Œ
                now = datetime.datetime.now(pytz.timezone(timezone))
                default_time = now + datetime.timedelta(hours=1)
                time_found = f"{default_time.hour:02d}:{default_time.minute:02d}"
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡ºï¼ˆæ™‚åˆ»ãƒ»æ—¥ä»˜ä»¥å¤–ã®éƒ¨åˆ†ï¼‰
            message = text
            for pattern, _ in time_patterns + [(p, None) for p, _ in date_patterns]:
                message = re.sub(pattern, '', message)
            
            # ä¸è¦ãªå˜èªã‚’é™¤å»
            remove_words = ["ã«", "ã‚’", "æ€ã„å‡ºã•ã›ã¦", "æ•™ãˆã¦", "ãŠçŸ¥ã‚‰ã›", "ã‚¢ãƒ©ãƒ¼ãƒ ", "è¨­å®š", "ã—ã¦"]
            for word in remove_words:
                message = message.replace(word, "")
            message = message.strip()
            
            if not message:
                message = "ã‚¢ãƒ©ãƒ¼ãƒ "
            
            result = {
                "date": date_found.strftime("%Y-%m-%d"),
                "time": time_found,
                "timezone": timezone,
                "message": message
            }
            
            self.logger.info(f"âœ… [ALARM_PARSE] Parsed result: {result}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ [ALARM_PARSE] Error parsing alarm text: {e}")
            return None
    
    def _get_next_date_with_day(self, day: int, timezone: str) -> datetime.date:
        """æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ã®æ¬¡ã®è©²å½“æ—¥ã‚’å–å¾—"""
        try:
            now = datetime.datetime.now(pytz.timezone(timezone))
            current_day = now.day
            
            if day > current_day:
                # ä»Šæœˆã®æŒ‡å®šæ—¥
                return now.replace(day=day).date()
            else:
                # æ¥æœˆã®æŒ‡å®šæ—¥
                if now.month == 12:
                    next_month = now.replace(year=now.year + 1, month=1, day=day)
                else:
                    next_month = now.replace(month=now.month + 1, day=day)
                return next_month.date()
        except:
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ˜æ—¥ã‚’è¿”ã™
            return (datetime.datetime.now(pytz.timezone(timezone)) + datetime.timedelta(days=1)).date()

class MessageTextParser(FlexibleTextParser):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ç”¨ã®è‡ªç„¶è¨€èªå‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    async def parse_message_command_ai(self, text: str) -> Optional[Dict]:
        """AI APIã‚’ä½¿ç”¨ã—ãŸé«˜ç²¾åº¦è§£æ"""
        try:
            import httpx
            import json
            import os
            
            # OpenAI APIè¨­å®š
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                self.logger.warning("âš ï¸ [AI_PARSE] OpenAI API key not found, falling back to regex")
                return self.parse_message_command_legacy(text)
            
            prompt = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®æ„å›³ã‚’è§£æã—ã¦ãã ã•ã„ã€‚
é€ä¿¡ç›¸æ‰‹ã®åå‰ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’JSONã§è¿”ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ: "{text}"

æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›å½¢å¼:
{{"recipient": "ç›¸æ‰‹ã®åå‰", "message": "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹"}}

é‡è¦ï¼šåå‰ã®èª­ã¿æ–¹ã¯æŸ”è»Ÿã«èªè­˜ã—ã¦ãã ã•ã„ã€‚
- æ¼¢å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã®é•ã„ã¯ç„¡è¦–
- ã€Œå›ã€ã€Œãã‚“ã€ã€Œãã¿ã€ãªã©èª­ã¿æ–¹ã®é•ã„ã¯ç„¡è¦–
- ä¾‹ãˆã°ã€Œã†ã‚“ã¡ãã‚“ã€ã€Œã†ã‚“ã¡å›ã€ã€Œã†ã‚“ã¡ãã¿ã€ã¯å…¨ã¦åŒã˜åå‰ã¨ã—ã¦èªè­˜
- æ•¬ç§°ï¼ˆã•ã‚“ã€å›ã€ã¡ã‚ƒã‚“ã€ãã‚“ï¼‰ã¯é™¤å»ã—ã¦ãã ã•ã„ã€‚

é€ä¿¡ã®æ„å›³ãŒãªã„å ´åˆã¯nullã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "gpt-4o-mini",
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": 100,
                        "temperature": 0
                    },
                    timeout=10.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data["choices"][0]["message"]["content"]
                    
                    try:
                        result = json.loads(content)
                        if result and result.get("recipient") and result.get("message"):
                            result["action"] = "send_message"
                            self.logger.info(f"âœ… [AI_PARSE] AIè§£ææˆåŠŸ: {result}")
                            return result
                    except json.JSONDecodeError:
                        self.logger.error(f"âŒ [AI_PARSE] JSONè§£æå¤±æ•—: {content}")
                else:
                    self.logger.error(f"âŒ [AI_PARSE] APIå‘¼ã³å‡ºã—å¤±æ•—: {response.status_code}")
                    
        except Exception as e:
            self.logger.error(f"âŒ [AI_PARSE] AIè§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ­£è¦è¡¨ç¾æ–¹å¼
        self.logger.info("ğŸ”„ [AI_PARSE] Falling back to regex parsing")
        return self.parse_message_command_legacy(text)

    async def parse_message_command(self, text: str) -> Optional[Dict]:
        """
        ãƒ¡ã‚¤ãƒ³ã®è§£æãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆAIå„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
        """
        # ã¾ãšAIè§£æã‚’è©¦è¡Œ
        result = await self.parse_message_command_ai(text)
        if result:
            return result
        
        # AIè§£æãŒå¤±æ•—ã—ãŸå ´åˆã¯æ­£è¦è¡¨ç¾æ–¹å¼
        return self.parse_message_command_legacy(text)
    
    def parse_message_command_regex(self, text: str) -> Optional[Dict]:
        """
        æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ã®è§£æï¼ˆæŸ”è»Ÿç‰ˆï¼‰
        """
        try:
            self.logger.info(f"ğŸ” [MESSAGE_PARSE] Parsing message text: '{text}'")
            
            # é€ä¿¡ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            send_keywords = ["ä¼ãˆã¦", "é€ã£ã¦", "é€ä¿¡ã—ã¦", "é€ã‚‹", "é€ä¿¡", "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", "æ‰‹ç´™æ›¸ã„ã¦", "ãƒ¬ã‚¿ãƒ¼"]
            
            # é€ä¿¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            has_send_keyword = any(keyword in text for keyword in send_keywords)
            if not has_send_keyword:
                return None
            
            # æŸ”è»Ÿãªè§£æï¼šåå‰å€™è£œã‚’æŠ½å‡º
            potential_names = self._extract_potential_names(text)
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸éƒ¨åˆ†ã‚’æŠ½å‡º
            message_part = self._extract_message_part(text, potential_names)
            
            if potential_names and message_part:
                # æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„åå‰ã‚’é¸æŠ
                best_name = potential_names[0]
                
                parsed_result = {
                    "recipient": best_name,
                    "message": message_part,
                    "action": "send_message"
                }
                
                self.logger.info(f"âœ… [MESSAGE_PARSE] Flexible parsed result: {parsed_result}")
                return parsed_result
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ [MESSAGE_PARSE] Error parsing message text: {e}")
            return None
    
    def _extract_potential_names(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åå‰å€™è£œã‚’æŠ½å‡º"""
        names = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã€Œã€œã•ã‚“ã€ã€Œã€œå›ã€ã€Œã€œã¡ã‚ƒã‚“ã€
        name_patterns = [
            r'(\w+)ã•ã‚“',
            r'(\w+)å›',
            r'(\w+)ã¡ã‚ƒã‚“',
        ]
        
        for pattern in name_patterns:
            matches = re.findall(pattern, text)
            names.extend(matches)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ã€Œã€œã«ã€ã€Œã€œã¸ã€ã®å‰ã®å˜èª
        target_patterns = [
            r'(\w+)ã«(?=.*(?:ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡))',
            r'(\w+)ã¸(?=.*(?:ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡))',
        ]
        
        for pattern in target_patterns:
            matches = re.findall(pattern, text)
            names.extend(matches)
        
        # é‡è¤‡é™¤å»ãƒ»æ­£è¦åŒ–
        unique_names = []
        for name in names:
            clean_name = name.replace("ã•ã‚“", "").replace("å›", "").replace("ã¡ã‚ƒã‚“", "").strip()
            if clean_name and clean_name not in unique_names:
                unique_names.append(clean_name)
        
        return unique_names
    
    def _extract_message_part(self, text: str, names: List[str]) -> str:
        """åå‰ã¨é€ä¿¡ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤ã„ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸éƒ¨åˆ†ã‚’æŠ½å‡º"""
        message = text
        
        # é€ä¿¡ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å»
        send_words = ["ä¼ãˆã¦", "é€ã£ã¦", "é€ä¿¡ã—ã¦", "é€ã‚‹", "é€ä¿¡", "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", "æ‰‹ç´™æ›¸ã„ã¦", "ãƒ¬ã‚¿ãƒ¼"]
        for word in send_words:
            message = message.replace(word, "")
        
        # åå‰é–¢é€£ã‚’é™¤å»
        for name in names:
            variations = [f"{name}ã•ã‚“", f"{name}å›", f"{name}ã¡ã‚ƒã‚“", name]
            for variation in variations:
                message = message.replace(variation, "")
        
        # åŠ©è©ãƒ»æ¥ç¶šè©ã‚’é™¤å»
        particles = ["ã«", "ã¸", "ã¨", "ã£ã¦", "ã‚’"]
        for particle in particles:
            message = message.replace(particle, "")
        
        return message.strip()
    
    def parse_message_command_legacy(self, text: str) -> Optional[Dict]:
        """
        å¾“æ¥ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ï¼‰
        """
        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            message_patterns = [
                # é€šå¸¸é †åº: ã€Œç”°ä¸­ã•ã‚“ã«ãŠç–²ã‚Œæ§˜ã¨é€ã£ã¦ã€
                (r'(.+?)ã«(.+?)ã¨?(ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡ã—ã¦|é€ã‚‹|é€ä¿¡|ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)', lambda m: {"recipient": m.group(1).strip(), "message": m.group(2).strip()}),
                (r'(.+?)ã¸(.+?)ã¨?(ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡ã—ã¦|é€ã‚‹|é€ä¿¡|ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)', lambda m: {"recipient": m.group(1).strip(), "message": m.group(2).strip()}),
                (r'(.+?)ã•ã‚“ã«(.+?)ã¨?(ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡ã—ã¦|é€ã‚‹|é€ä¿¡)', lambda m: {"recipient": m.group(1).strip(), "message": m.group(2).strip()}),
                # é€†é †åº: ã€Œã“ã‚“ã«ã¡ã¯ã£ã¦ç”°ä¸­ã•ã‚“ã«é€ã£ã¦ã€
                (r'(.+?)ã£ã¦(.+?)ã«(ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡ã—ã¦|é€ã‚‹|é€ä¿¡)', lambda m: {"recipient": m.group(2).strip(), "message": m.group(1).strip()}),
                (r'(.+?)ã£ã¦(.+?)ã¸(ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡ã—ã¦|é€ã‚‹|é€ä¿¡)', lambda m: {"recipient": m.group(2).strip(), "message": m.group(1).strip()}),
                (r'(.+?)ã£ã¦(.+?)ã•ã‚“ã«(ä¼ãˆã¦|é€ã£ã¦|é€ä¿¡ã—ã¦|é€ã‚‹|é€ä¿¡)', lambda m: {"recipient": m.group(2).strip(), "message": m.group(1).strip()}),
                # æ‰‹ç´™ãƒ‘ã‚¿ãƒ¼ãƒ³
                (r'(.+?)ã«(.+?)ã£ã¦?(æ‰‹ç´™æ›¸ã„ã¦|ãƒ¬ã‚¿ãƒ¼)', lambda m: {"recipient": m.group(1).strip(), "message": m.group(2).strip()}),
                (r'(.+?)ã¸(.+?)ã£ã¦?(æ‰‹ç´™æ›¸ã„ã¦|ãƒ¬ã‚¿ãƒ¼)', lambda m: {"recipient": m.group(1).strip(), "message": m.group(2).strip()}),
            ]
            
            for pattern, extractor in message_patterns:
                match = re.search(pattern, text)
                if match:
                    result = extractor(match)
                    
                    # å—ä¿¡è€…åã®æ­£è¦åŒ–
                    recipient = result["recipient"]
                    recipient = recipient.replace("ã•ã‚“", "").replace("å›", "").replace("ã¡ã‚ƒã‚“", "").strip()
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ­£è¦åŒ–
                    message = result["message"]
                    message = message.replace("ã¨", "").strip()
                    
                    if recipient and message:
                        parsed_result = {
                            "recipient": recipient,
                            "message": message,
                            "action": "send_message"
                        }
                        
                        return parsed_result
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ [MESSAGE_PARSE] Error parsing message text: {e}")
            return None
    
    def find_similar_friend_name(self, input_name: str, friend_list: List[str]) -> Optional[str]:
        """
        æŸ”è»Ÿãªå‹é”åæ¤œç´¢ï¼ˆãƒ¡ãƒ¢ãƒªãƒ¼æ¤œç´¢ã®é¡ä¼¼åº¦è¨ˆç®—ã‚’æ´»ç”¨ï¼‰
        ã€Œç”°ä¸­ã€â†’ã€Œç”°ä¸­å¤ªéƒã€ã®ã‚ˆã†ãªéƒ¨åˆ†ãƒãƒƒãƒãƒ³ã‚°ã‚’å®Ÿç¾
        """
        try:
            self.logger.info(f"ğŸ” [FRIEND_SEARCH] Searching for '{input_name}' in friend list: {friend_list}")
            
            best_match = None
            best_similarity = 0.0
            similarity_threshold = 0.3  # ãƒ¡ãƒ¢ãƒªãƒ¼æ¤œç´¢ã¨åŒã˜é–¾å€¤
            
            for friend_name in friend_list:
                similarity = self.calculate_similarity(input_name, friend_name)
                self.logger.info(f"ğŸ” [FRIEND_SIMILARITY] '{input_name}' vs '{friend_name}': {similarity}")
                
                if similarity > best_similarity and similarity > similarity_threshold:
                    best_similarity = similarity
                    best_match = friend_name
            
            if best_match:
                self.logger.info(f"âœ… [FRIEND_MATCH] Best match for '{input_name}': '{best_match}' (similarity: {best_similarity})")
                return best_match
            else:
                self.logger.info(f"âŒ [FRIEND_MATCH] No suitable match found for '{input_name}'")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ [FRIEND_SEARCH] Error in friend name search: {e}")
            return None

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
alarm_parser = AlarmTextParser()
message_parser = MessageTextParser()
