"""
Server2 style audio processing for xiaozhi-esp32-server3
Complete port of server2's audio handling logic
"""
import asyncio
import json
import struct
import time
import io
import wave
import uuid
from typing import List, Optional
from utils.logger import setup_logger

logger = setup_logger()

class AudioHandlerServer2:
    def __init__(self, websocket_handler):
        self.handler = websocket_handler
        self.asr_audio = []  # List of Opus frames
        self.client_have_voice = False
        self.client_voice_stop = False
        self.last_activity_time = time.time() * 1000
        
        # RMSãƒ™ãƒ¼ã‚¹éŸ³å£°æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ  (server2æº–æ‹ )
        self.client_have_voice = False
        self.last_voice_activity_time = time.time() * 1000  # milliseconds
        self.silence_threshold_ms = 2000  # 2ç§’ç„¡éŸ³ã§å‡¦ç†é–‹å§‹ (é•·ã„ç™ºè©±å¯¾å¿œ)
        self.rms_threshold = 250  # RMSé–¾å€¤ã‚’ä¸Šã’ã¦éæ•åå¿œã‚’æŠ‘åˆ¶
        self.voice_frame_count = 0  # é€£ç¶šéŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        self.silence_frame_count = 0  # é€£ç¶šç„¡éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        self.is_processing = False  # é‡è¤‡å‡¦ç†é˜²æ­¢ãƒ•ãƒ©ã‚°
        self.tts_in_progress = False  # TTSä¸­ã¯éŸ³å£°æ¤œçŸ¥ä¸€æ™‚åœæ­¢
        self.client_is_speaking = False  # AIç™ºè©±ä¸­ãƒ•ãƒ©ã‚°ï¼ˆserver2æº–æ‹ ã‚¨ã‚³ãƒ¼é˜²æ­¢ï¼‰
        
        # RIDè¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ¤œç´¢ã—ã‚„ã™ã„ãƒ­ã‚°ç”¨ï¼‰
        self.current_request_id = None
        self.active_tts_rid = None  # ç¾åœ¨å†ç”Ÿä¸­ã®TTS RID
        
        # Server2æº–æ‹ : wake_guardæ©Ÿèƒ½ï¼ˆé€£ç¶šç™ºè©±å¯¾å¿œï¼‰
        self.wake_until = 0  # ã“ã®æ™‚é–“ã¾ã§å¼·åˆ¶çš„ã«ç™ºè©±ç¶™ç¶šã¨åˆ¤å®š
        self.wake_guard_ms = 500  # æœ‰éŸ³å¾Œ500msé–“ã¯ç™ºè©±ç¶™ç¶šï¼ˆserver2ã®300msã‚ˆã‚Šé•·ã‚ï¼‰
        
        # TTSçµ‚äº†å¾Œã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆéŸ³éŸ¿å›ã‚Šè¾¼ã¿é˜²æ­¢ï¼‰
        self.tts_cooldown_until = 0  # ã“ã®æ™‚é–“ã¾ã§éŸ³å£°å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
        self.tts_cooldown_ms = 800  # TTSçµ‚äº†å¾Œ800msã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆã‚¨ã‚³ãƒ¼å®Œå…¨å®‰å®šåŒ–ï¼‰
        
        # Initialize Opus decoder
        try:
            import opuslib_next
            self.opus_decoder = opuslib_next.Decoder(16000, 1)
            logger.info("Opus decoder initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Opus decoder: {e}")
            self.opus_decoder = None

    async def handle_audio_frame(self, audio_data: bytes):
        """Handle single audio frame with RMS-based silence detection (server2æº–æ‹ )"""
        try:
            # Drop tiny DTX packets (server2 style)
            current_time = time.time() * 1000
            
            # TTSçµ‚äº†å¾Œã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ã®ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å„ªå…ˆï¼‰
            if current_time < self.tts_cooldown_until:
                logger.debug(f"[TTS_COOLDOWN] éŸ³å£°å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—: æ®‹ã‚Š{self.tts_cooldown_until - current_time:.0f}ms")
                return
            
            # æ³¨æ„: DTXãƒ•ã‚£ãƒ«ã‚¿ã¯Connection Handlerã§æ—¢ã«å‡¦ç†æ¸ˆã¿
            # ã“ã“ã§ã¯éŸ³å£°å‡¦ç†ã®ã¿å®Ÿè¡Œ
                
            # 1ãƒã‚¤ãƒˆDTXã¯è¿½åŠ ã§500msåˆ¶é™ï¼ˆäºŒé‡é˜²å¾¡ï¼‰
            if len(audio_data) == 1:
                if not hasattr(self, 'last_dtx_time'):
                    self.last_dtx_time = 0
                if current_time - self.last_dtx_time < 500:
                    return
                self.last_dtx_time = current_time
                logger.debug(f"[DTX_KEEPALIVE] 1ãƒã‚¤ãƒˆDTX keepaliveè¨±å¯")
                
            # é‡è¤‡å‰Šé™¤: ä¸Šè¨˜ã§æ—¢ã«DTXãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿

            # RMSãƒ™ãƒ¼ã‚¹éŸ³å£°æ¤œçŸ¥ (server2æº–æ‹ )
            is_voice = await self._detect_voice_with_rms(audio_data)
            
            # Server2æº–æ‹ : wake_guardæ©Ÿèƒ½ï¼ˆæœ‰éŸ³æ¤œçŸ¥æ™‚ã®å‡¦ç†ï¼‰
            if is_voice:
                self.last_voice_activity_time = current_time
                # wake_guardè¨­å®š: æœ‰éŸ³å¾Œä¸€å®šæ™‚é–“ã¯å¼·åˆ¶çš„ã«ç™ºè©±ç¶™ç¶šã¨åˆ¤å®š
                self.wake_until = current_time + self.wake_guard_ms
                logger.info(f"ğŸ”¥ [WAKE_GUARD] æœ‰éŸ³æ¤œçŸ¥: current={current_time}, wake_until={self.wake_until}, guard_ms={self.wake_guard_ms}")

            # Server2æº–æ‹ : TTSä¸­ã®ãƒã‚¤ã‚¯åˆ¶å¾¡ï¼ˆå®Œå…¨ã‚¨ã‚³ãƒ¼é˜²æ­¢ï¼‰
            if self.client_is_speaking:
                # AIç™ºè©±ä¸­ã¯å…¨éŸ³å£°ã‚’å®Œå…¨ç„¡è¦–ï¼ˆãƒã‚¤ã‚¯ã‚ªãƒ•çŠ¶æ…‹ï¼‰
                logger.info(f"ğŸ”‡ [MIC_OFF_AUDIO] AIç™ºè©±ä¸­ãƒã‚¤ã‚¯ã‚ªãƒ•: {len(audio_data)}B - å…¨éŸ³å£°ç ´æ£„ï¼ˆã‚¨ã‚³ãƒ¼å®Œå…¨é˜²æ­¢ï¼‰")
                return  # å…¨éŸ³å£°å®Œå…¨ç ´æ£„
            
            # ãƒ‡ãƒãƒƒã‚°: RMS VADå‹•ä½œç¢ºèª
            # logger.info(f"ğŸ” [VAD_DEBUG] RMSæ¤œçŸ¥çµæœ: voice={is_voice}, audio_size={len(audio_data)}B")  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã§å‰Šé™¤
            
            # Store audio frame regardless (server2 style)
            self.asr_audio.append(audio_data)
            
            # è©³ç´°ãƒ•ãƒ¬ãƒ¼ãƒ è“„ç©ãƒ­ã‚° + DTXçµ±è¨ˆ
            if len(self.asr_audio) % 30 == 0:  # 30ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ãƒ­ã‚°
                dtx_drop = getattr(self, 'dtx_drop_count', 0)
                cooldown_active = current_time < self.tts_cooldown_until
                logger.info(f"ğŸ“¦ [FRAME_ACCUMULATION] è“„ç©ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(self.asr_audio)}, æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ : {len(audio_data)}B, éŸ³å£°æ¤œçŸ¥: {is_voice}, DTXãƒ‰ãƒ­ãƒƒãƒ—: {dtx_drop}, ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³: {cooldown_active}")
            self.asr_audio = self.asr_audio[-100:]  # Keep more frames
            
            # logger.info(f"[AUDIO_TRACE] Frame: {len(audio_data)}B, RMS_voice={is_voice}, frames={len(self.asr_audio)}")  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã§å‰Šé™¤
            
            if is_voice:
                # éŸ³å£°æ¤œå‡ºæ™‚ã«TTSåœæ­¢ãƒ•ãƒ©ã‚°ã‚‚ãƒªã‚»ãƒƒãƒˆï¼ˆæ¬¡ã®ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹ï¼‰
                if self.tts_in_progress:
                    logger.info("ã€TTSå¾ŒéŸ³å£°æ¤œçŸ¥ã€‘æ¬¡ã®ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹ - éŸ³å£°æ¤œçŸ¥å†é–‹")
                    self.tts_in_progress = False
                
                # éŸ³å£°æ¤œå‡º
                if not self.client_have_voice:
                    logger.info("ã€éŸ³å£°é–‹å§‹æ¤œå‡ºã€‘éŸ³å£°è“„ç©é–‹å§‹ - ç„¡éŸ³æ¤œçŸ¥ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹")
                self.client_have_voice = True
                self.last_voice_activity_time = current_time
                self.voice_frame_count += 1
                self.silence_frame_count = 0
            else:
                # ç„¡éŸ³æ¤œå‡º
                self.silence_frame_count += 1
                
                # server2æº–æ‹ : éŸ³å£°é–‹å§‹å¾Œã®ã¿ç„¡éŸ³æ¤œçŸ¥å®Ÿè¡Œ
                if self.client_have_voice:
                    silence_duration = current_time - self.last_voice_activity_time
                    # logger.info(f"ã€ç„¡éŸ³ç¶™ç¶šã€‘{silence_duration:.0f}ms / {self.silence_threshold_ms}ms (æœ‰éŸ³å¾Œ)")  # ãƒ­ã‚°å‰Šæ¸›
                    
                    # Server2æº–æ‹ : wake_guardæœŸé–“ä¸­ã¯ç„¡éŸ³æ¤œçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if current_time < self.wake_until:
                        logger.info(f"ğŸ›¡ï¸ [WAKE_GUARD] ç„¡éŸ³æ¤œçŸ¥ã‚¹ã‚­ãƒƒãƒ—: æ®‹ã‚Š{self.wake_until - current_time:.0f}ms")
                        return
                    
                    if silence_duration >= self.silence_threshold_ms and len(self.asr_audio) > 5 and not self.is_processing:
                        logger.info(f"ğŸŸ XIAOZHI_SILENCE_DETECTğŸŸ  â€»ã“ã“ã‚’é€ã£ã¦ver2_SILENCE_DETECTâ€» ã€ç„¡éŸ³æ¤œçŸ¥å®Œäº†ã€‘{silence_duration:.0f}msç„¡éŸ³ - éŸ³å£°å‡¦ç†é–‹å§‹ (æœ‰éŸ³â†’ç„¡éŸ³)")
                        logger.info(f"ğŸ” [SILENCE_DEBUG] threshold={self.silence_threshold_ms}ms, audio_frames={len(self.asr_audio)}, is_processing={self.is_processing}")
                        logger.info(f"ğŸ” [SILENCE_DEBUG] last_voice_time={self.last_voice_activity_time}, current_time={current_time}")
                        await self._process_voice_stop()
                    elif silence_duration >= self.silence_threshold_ms:
                        # é–¾å€¤ã¯è¶…ãˆã¦ã„ã‚‹ãŒä»–ã®æ¡ä»¶ã§å‡¦ç†ã•ã‚Œãªã„å ´åˆ
                        logger.warning(f"ğŸŸ¡ [SILENCE_DEBUG] Threshold exceeded but not processing: duration={silence_duration:.0f}ms, audio_frames={len(self.asr_audio)}, is_processing={self.is_processing}")
                    elif silence_duration >= (self.silence_threshold_ms * 0.8):
                        # é–¾å€¤80%ä»¥ä¸Šã§è­¦å‘Š
                        logger.debug(f"âš ï¸ [SILENCE_DEBUG] Approaching threshold: {silence_duration:.0f}ms / {self.silence_threshold_ms}ms")
                else:
                    # æœ‰éŸ³æ¤œçŸ¥å‰ã®ç„¡éŸ³ã¯ç„¡è¦–
                    logger.debug(f"[SILENCE_IGNORE] æœ‰éŸ³æ¤œçŸ¥å‰ã®ç„¡éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ : {self.silence_frame_count}")

        except Exception as e:
            logger.error(f"Error handling audio frame: {e}")

    async def _process_voice_stop(self):
        """Process accumulated audio when voice stops (server2 style)"""
        try:
            # æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDç”Ÿæˆ
            rid = str(uuid.uuid4())[:8]
            self.current_request_id = rid
            
            # ğŸ¯ æ¤œç´¢å¯èƒ½ãƒ­ã‚°: handle_voice_stop
            logger.info(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_START: frames={len(self.asr_audio)}, is_processing={self.is_processing}, tts_active={getattr(self.handler, 'tts_active', False)}")
            
            # TTSä¸­ã¯éŸ³å£°å‡¦ç†ã‚’å®Œå…¨ã«ç„¡è¦–
            if self.tts_in_progress:
                logger.warning(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_BLOCKED: TTSä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                return
            
            # Set processing flag at the start
            if self.is_processing:
                logger.warning(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_DUPLICATE: æ—¢ã«å‡¦ç†ä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                return
                
            self.is_processing = True
            logger.info(f"ğŸ”„ [PROCESSING] Starting voice processing")
                
            # Check minimum requirement (èª¿æ•´: é•·ã„ç™ºè©±ã‚’ç¢ºå®Ÿã«å‡¦ç†)
            estimated_pcm_bytes = len(self.asr_audio) * 1920  # Each Opus frame ~1920 PCM bytes
            min_pcm_bytes = 15000  # èª¿æ•´: 24000ã‹ã‚‰15000ã«ä¸‹ã’ã¦é•·ã„ç™ºè©±ã‚‚å‡¦ç†
            
            logger.info(f"[AUDIO_TRACE] Voice stop: {len(self.asr_audio)} frames, ~{estimated_pcm_bytes} PCM bytes")
            
            if estimated_pcm_bytes < min_pcm_bytes:
                logger.info(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_TOO_SMALL: {estimated_pcm_bytes} < {min_pcm_bytes}, discarding")
                self._reset_audio_state()
                return

            # Process accumulated frames
            audio_frames = self.asr_audio.copy()
            self._reset_audio_state()
            
            logger.info(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_PROCESSING: Converting {len(audio_frames)} frames to WAV")
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ è©³ç´°åˆ†æ
            total_bytes = sum(len(frame) for frame in audio_frames)
            frame_sizes = [len(frame) for frame in audio_frames[:10]]  # æœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ 
            logger.info(f"ğŸ”¥ RID[{rid}] FRAME_ANALYSIS: total_bytes={total_bytes}, frame_sizes={frame_sizes}...")
            
            # Convert to WAV using server2 method
            wav_data = await self._opus_frames_to_wav(audio_frames)
            if wav_data:
                # Send to ASR
                logger.info(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_ASR_START: wav_size={len(wav_data)}")
                await self._process_with_asr(wav_data, rid)
            else:
                logger.warning(f"ğŸ”¥ RID[{rid}] HANDLE_VOICE_STOP_FAILED: WAVå¤‰æ›å¤±æ•—")

        except Exception as e:
            logger.error(f"Error processing voice stop: {e}")

    async def _opus_frames_to_wav(self, opus_frames: List[bytes]) -> Optional[bytes]:
        """Convert Opus frames to WAV (server2 style)"""
        try:
            if not self.opus_decoder:
                logger.error("Opus decoder not available")
                return None

            # Decode Opus frames to PCM (server2 style)
            pcm_data = []
            buffer_size = 960  # 60ms at 16kHz
            
            for i, opus_packet in enumerate(opus_frames):
                try:
                    if not opus_packet or len(opus_packet) == 0:
                        continue
                    
                    pcm_frame = self.opus_decoder.decode(opus_packet, buffer_size)
                    if pcm_frame and len(pcm_frame) > 0:
                        pcm_data.append(pcm_frame)
                        
                except Exception as e:
                    logger.warning(f"Opus decode error, skip packet {i}: {e}")
                    continue

            if not pcm_data:
                logger.warning("No valid PCM data from Opus frames")
                return None

            # Create WAV file from PCM data (server2 style)
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)      # mono
                wav_file.setsampwidth(2)      # 16-bit
                wav_file.setframerate(16000)  # 16kHz
                wav_file.writeframes(b''.join(pcm_data))
            
            wav_buffer.seek(0)
            wav_data = wav_buffer.read()
            
            total_pcm_bytes = sum(len(frame) for frame in pcm_data)
            logger.info(f"[AUDIO_TRACE] Opus->WAV: {len(opus_frames)} frames -> {total_pcm_bytes} PCM bytes -> {len(wav_data)} WAV bytes")
            
            return wav_data

        except Exception as e:
            logger.error(f"Error converting Opus to WAV: {e}")
            return None

    async def _process_with_asr(self, wav_data: bytes, rid: str = None):
        """Process WAV data with ASR"""
        try:
            if not rid:
                rid = str(uuid.uuid4())[:8]
            
            # ğŸ¯ æ¤œç´¢å¯èƒ½ãƒ­ã‚°: ASRå‡¦ç†é–‹å§‹
            logger.info(f"ğŸ”¥ RID[{rid}] ASR_START: wav_size={len(wav_data)}")
            
            # ASRé‡è¤‡å‡¦ç†é˜²æ­¢
            if hasattr(self, '_asr_processing') and self._asr_processing:
                logger.warning(f"ğŸš¨ [ASR_DUPLICATE_PREVENT] ASR already in progress, skipping")
                return
                
            self._asr_processing = True
            
            # Create file-like object for ASR
            wav_file = io.BytesIO(wav_data)
            wav_file.name = "audio.wav"
            
            # Call ASR service
            logger.info(f"ğŸ”¥ RID[{rid}] ASR_WHISPER_START: Calling OpenAI Whisper API")
            transcribed_text = await self.handler.asr_service.transcribe(wav_file)
            logger.info(f"ğŸ”¥ RID[{rid}] ASR_WHISPER_RESULT: '{transcribed_text}' (len: {len(transcribed_text) if transcribed_text else 0})")
            
            if transcribed_text and transcribed_text.strip():
                logger.info(f"ğŸ”¥ RID[{rid}] START_TO_CHAT_TRIGGER: Sending '{transcribed_text}' to LLM")
                await self.handler.process_text(transcribed_text, rid)
            else:
                logger.warning(f"ğŸ”¥ RID[{rid}] ASR_EMPTY: No valid transcription")

        except Exception as e:
            logger.error(f"ğŸ”¥ RID[{rid}] ASR_ERROR: {e}")
        finally:
            self._asr_processing = False
            
            # TTSä¸­ã¯ is_processing ã‚’ç¶­æŒï¼ˆTTSä¸­æ–­é˜²æ­¢ï¼‰
            # WebSocketãƒãƒ³ãƒ‰ãƒ©ã®tts_activeã¨tts_in_progressã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
            tts_active = getattr(self.handler, 'tts_active', False) if hasattr(self, 'handler') else False
            
            if not self.tts_in_progress and not tts_active:
                self.is_processing = False
                logger.info(f"ğŸ”¥ RID[{rid}] ASR_END: Processing complete, is_processing=False")
            else:
                logger.warning(f"ğŸ”¥ RID[{rid}] ASR_END_TTS_PROTECTION: TTSä¸­ã®ãŸã‚is_processingç¶­æŒ (tts_in_progress={self.tts_in_progress}, tts_active={tts_active})")

    async def _detect_voice_with_rms(self, audio_data: bytes) -> bool:
        """RMSãƒ™ãƒ¼ã‚¹éŸ³å£°æ¤œçŸ¥ (server2 WebRTC VADæº–æ‹ )"""
        try:
            if not self.opus_decoder:
                # Fallback: ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹åˆ¤å®š
                return len(audio_data) > 30
                
            # Opus â†’ PCMå¤‰æ›
            pcm_data = self.opus_decoder.decode(audio_data, 960)  # 60ms frame
            if not pcm_data or len(pcm_data) < 4:
                return False
                
            # RMSè¨ˆç®— (server2æº–æ‹ )
            import audioop
            try:
                rms_value = audioop.rms(pcm_data, 2)  # 16-bit samples
                is_voice = rms_value >= self.rms_threshold
                logger.info(f"[RMS_VAD] rms={rms_value} threshold={self.rms_threshold} voice={is_voice}")
                return is_voice
            except Exception as e:
                logger.debug(f"RMS calculation failed: {e}")
                # Fallback: numpy-based energy calculation
                import numpy as np
                pcm_int16 = np.frombuffer(pcm_data, dtype=np.int16)
                if pcm_int16.size > 0:
                    energy = np.mean(np.abs(pcm_int16))
                    is_voice = energy >= 100  # Conservative threshold
                    logger.info(f"[ENERGY_VAD] energy={energy:.1f} voice={is_voice}")
                    return is_voice
                return False
                
        except Exception as e:
            logger.debug(f"Voice detection error: {e}")
            return len(audio_data) > 20  # Safe fallback

    def _detect_voice_activity(self, audio_data: bytes) -> bool:
        """Detect voice activity using energy analysis (server2 style)"""
        try:
            # Size-based initial filter (server2 style)
            if len(audio_data) <= 10:  # Very small packets are likely DTX/silence
                return False
            
            # Decode to PCM for energy analysis (if possible)
            if self.opus_decoder and len(audio_data) > 10:
                try:
                    pcm_data = self.opus_decoder.decode(audio_data, 960)  # 60ms frame
                    if pcm_data and len(pcm_data) > 0:
                        # Calculate energy (RMS-like)
                        import numpy as np
                        pcm_int16 = np.frombuffer(pcm_data, dtype=np.int16)
                        if pcm_int16.size > 0:
                            energy = np.mean(np.abs(pcm_int16))
                            # Energy threshold (èª¿æ•´: ã‚ˆã‚Šæ•æ„Ÿã«)
                            voice_detected = energy >= 80  # ã‚ˆã‚Šæ•æ„Ÿãªé–¾å€¤ã§å°å£°ã‚‚æ‹¾ã†
                            logger.info(f"[VAD_ENERGY] pkt={len(audio_data)}B, energy={energy:.1f}, voice={voice_detected}")
                            return voice_detected
                except Exception as e:
                    logger.debug(f"[VAD] Opus decode failed for energy analysis: {e}")
            
            # Fallback: size-based detection (server2 backup method)
            voice_detected = len(audio_data) > 30  # Reasonable threshold for voice packets
            logger.info(f"[VAD_SIZE] pkt={len(audio_data)}B, voice={voice_detected}")
            return voice_detected
            
        except Exception as e:
            logger.error(f"VAD detection error: {e}")
            return len(audio_data) > 20  # Safe fallback

    def _reset_audio_state(self):
        """Reset audio state (server2 style with RMS VAD reset)"""
        self.asr_audio.clear()
        self.client_have_voice = False
        self.client_voice_stop = False
        self.voice_frame_count = 0
        self.silence_frame_count = 0
        self.last_voice_activity_time = time.time() * 1000
        
        # TTSä¸­ã¯ is_processing ã‚’ãƒªã‚»ãƒƒãƒˆã—ãªã„ï¼ˆTTSä¸­æ–­é˜²æ­¢ï¼‰
        if not self.tts_in_progress:
            self.is_processing = False
            logger.info("[AUDIO_TRACE] Audio state reset (is_processingã‚‚ãƒªã‚»ãƒƒãƒˆ)")
        else:
            logger.warning(f"ğŸš¨ [IS_PROCESSING_PROTECTION] TTSä¸­ã®ãŸã‚is_processingç¶­æŒ (tts_in_progress={self.tts_in_progress})")
            
        # is_processingå¤‰æ›´ã‚’è©³ç´°ãƒ­ã‚°
        logger.info(f"ğŸ” [IS_PROCESSING_STATE] After _reset_audio_state: is_processing={self.is_processing}, tts_in_progress={self.tts_in_progress}")
