import asyncio
import json
import struct
import uuid
import io
import threading
import time
from typing import Dict, Any, Optional
from collections import deque
from aiohttp import web

class ConnectionClosedError(Exception):
    """WebSocket connection closed exception"""
    pass

from config import Config
from utils.logger import setup_logger
from utils.auth import AuthManager, AuthError
from audio.asr import ASRService
from audio.tts import TTSService
from ai.llm import LLMService
from ai.memory import MemoryService
from audio_handler_server2 import AudioHandlerServer2

logger = setup_logger()

class ConnectionHandler:
    def __init__(self, websocket: web.WebSocketResponse, headers: Dict[str, str]):
        self.websocket = websocket
        self.headers = headers
        self.device_id = headers.get("device-id") or "unknown"
        self.client_id = headers.get("client-id") or str(uuid.uuid4())
        self.protocol_version = int(headers.get("protocol-version", "1"))
        import time as time_module  # ã‚¹ã‚³ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼å›é¿
        self.session_id = f"session_{int(time_module.time())}"  # Server2æº–æ‹ ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        
        self.asr_service = ASRService()
        self.tts_service = TTSService()
        self.llm_service = LLMService()
        self.memory_service = MemoryService()

        self.chat_history = deque(maxlen=10) # Store last 10 messages
        self.client_is_speaking = False
        self.stop_event = threading.Event() # For graceful shutdown (server2 style)
        self.session_id = str(uuid.uuid4())
        self.audio_format = "opus"  # Default format (ESP32 sends Opus like server2)
        self.features = {}
        self.close_after_chat = False  # Server2æº–æ‹ : ãƒãƒ£ãƒƒãƒˆå¾Œã®æ¥ç¶šåˆ¶å¾¡
        
        # Audio buffering (server2 style)
        self.asr_audio = []  # List of Opus frames (server2 style)
        self.client_have_voice = False
        self.client_voice_stop = False
        self.last_activity_time = time.time()
        
        # Server2æº–æ‹ : ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–ï¼ˆå…ƒã®180ç§’ã«æˆ»ã—ã¦è©³ç´°èª¿æŸ»ï¼‰
        self.timeout_seconds = 180  # 120 + 60ç§’ã®ãƒãƒƒãƒ•ã‚¡ï¼ˆESP32ã‚¨ãƒ©ãƒ¼åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ï¼‰
        self.timeout_task = None
        
        # Initialize server2-style audio handler
        self.audio_handler = AudioHandlerServer2(self)
        
        # Welcome message compatible with ESP32 (Server2æº–æ‹ )
        self.welcome_msg = {
            "type": "hello",
            "version": 1,  # â˜…é‡è¦â˜…ESP32ãŒæœŸå¾…ã™ã‚‹versionãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            "transport": "websocket", 
            "session_id": self.session_id,
            "audio_params": {
                "format": "opus",
                "sample_rate": 16000,
                "channels": 1,
                "frame_duration": 60  # Server2æº–æ‹ ã®60ms
            }
        }

        logger.info(f"ConnectionHandler initialized for device: {self.device_id}, protocol v{self.protocol_version}")

    async def handle_message(self, message):
        """Handle both text (JSON) and binary (audio) messages"""
        if isinstance(message, str):
            logger.info(f"ğŸ“¨ [DEBUG] Received TEXT message: {message[:100]}... from {self.device_id}")
            await self.handle_text_message(message)
        elif isinstance(message, bytes):
            # logger.info(f"ğŸ¤ [DEBUG] Received BINARY audio data: {len(message)} bytes from {self.device_id}")  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã§å‰Šé™¤
            await self.handle_binary_message(message)

    async def handle_text_message(self, message: str):
        try:
            msg_json = json.loads(message)
            msg_type = msg_json.get("type")

            if msg_type == "hello":
                await self.handle_hello_message(msg_json)
            elif msg_type == "abort":
                logger.info(f"Abort message received from {self.device_id}")
                self.client_is_speaking = False
            elif msg_type == "listen":
                await self.handle_listen_message(msg_json)
            elif msg_type == "text":
                text_input = msg_json.get("data", "")
                if text_input:
                    await self.process_text(text_input)
            else:
                logger.warning(f"Unknown message type from {self.device_id}: {msg_type}")

        except json.JSONDecodeError:
            logger.error(f"Invalid JSON from {self.device_id}: {message[:100]}...")
        except Exception as e:
            logger.error(f"Error handling text message from {self.device_id}: {e}")

    async def handle_binary_message(self, message: bytes):
        """Handle binary audio data based on protocol version"""
        try:
            # A. å…¥å£ã§è½ã¨ã™ï¼ˆæœ€é‡è¦ï¼‰- AIç™ºè©±ä¸­+ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­å®Œå…¨ãƒ–ãƒ­ãƒƒã‚¯
            now_ms = time.time() * 1000
            is_ai_speaking = hasattr(self, 'audio_handler') and getattr(self.audio_handler, 'client_is_speaking', False)
            is_cooldown = hasattr(self, 'audio_handler') and now_ms < getattr(self.audio_handler, 'tts_cooldown_until', 0)
            
            if is_ai_speaking or is_cooldown:
                # B. WebSocketå…¥å£ã§å¿…ãšè½ã¨ã™ï¼ˆæœ€é‡è¦ï¼‰
                # åŒä¸€ã®æ™‚åŸºã§ã‚¬ãƒ¼ãƒ‰ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡æ‘˜ã®é€šã‚Šï¼‰
                if not hasattr(self, 'ws_gate_drops'):
                    self.ws_gate_drops = 0
                if not hasattr(self, '_ws_block_count'):
                    self._ws_block_count = 0
                    
                self.ws_gate_drops += 1
                self._ws_block_count += 1
                
                # çµ±è¨ˆãƒ»ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                block_reason = "AIç™ºè©±ä¸­" if is_ai_speaking else f"ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­(æ®‹ã‚Š{int(getattr(self.audio_handler, 'tts_cooldown_until', 0) - now_ms)}ms)"
                
                # ãƒ­ã‚°ã¯30ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ï¼ˆè©³ç´°ç¢ºèªã®ãŸã‚é »åº¦ä¸Šã’ï¼‰
                if self._ws_block_count % 30 == 0:
                    logger.info(f"ğŸšª [WS_ENTRANCE_BLOCK] {block_reason}å…¥å£ãƒ–ãƒ­ãƒƒã‚¯: éå»30ãƒ•ãƒ¬ãƒ¼ãƒ å®Œå…¨ç ´æ£„ (ç´¯è¨ˆ={self.ws_gate_drops})")
                return  # å³åº§ã«ç ´æ£„
            
            # Server2æº–æ‹ : å°ãƒ‘ã‚±ãƒƒãƒˆã§ã‚‚æ´»å‹•æ™‚é–“ã‚’æ›´æ–°ï¼ˆESP32ã‹ã‚‰ã®ç¶™ç¶šé€šä¿¡ã‚’èªè­˜ï¼‰
            self.last_activity_time = time.time()
            
            # ãƒ‡ãƒãƒƒã‚°: ãƒ‘ã‚±ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’ãƒ­ã‚°ï¼ˆâ˜…å…¥å£ã‚¬ãƒ¼ãƒ‰é€šéâ˜… - AIéç™ºè©±ï¼†ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³å¤–ï¼‰
            if not hasattr(self, '_packet_log_count'):
                self._packet_log_count = 0
            self._packet_log_count += 1
            # é€šå¸¸æ™‚ã‚‚20ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ã«åˆ¶é™ï¼ˆãƒ­ã‚°è»½æ¸›ï¼‰
            if self._packet_log_count % 20 == 0:
                logger.info(f"ğŸ”§ [PACKET_DEBUG] â˜…å…¥å£ã‚¬ãƒ¼ãƒ‰é€šéâ˜… é€šå¸¸å‡¦ç†: éå»20ãƒ•ãƒ¬ãƒ¼ãƒ  (æœ€æ–°: {len(message)}B), protocol v{self.protocol_version}")
            
            # æ—§æ¥ã®å°ãƒ‘ã‚±ãƒƒãƒˆã‚¹ã‚­ãƒƒãƒ—ã‚’ä¸€æ™‚ç„¡åŠ¹åŒ–ï¼ˆServer2 Connection Handlerã§å‡¦ç†ï¼‰
            # if len(message) <= 12:  # Skip very small packets (DTX/keepalive) but keep activity alive
            #     logger.info(f"â­ï¸ [DEBUG] Skipping small packet: {len(message)} bytes (activity updated)")
            #     return
                
            if self.protocol_version == 2:
                # Protocol v2: version(2) + type(2) + reserved(2) + timestamp(4) + payload_size(4) + payload
                if len(message) < 14:
                    return
                version, msg_type, reserved, timestamp, payload_size = struct.unpack('>HHHII', message[:14])
                audio_data = message[14:14+payload_size]
            elif self.protocol_version == 3:
                # Protocol v3: type(1) + reserved(1) + payload_size(2) + payload
                if len(message) < 4:
                    return
                msg_type, reserved, payload_size = struct.unpack('>BBH', message[:4])
                audio_data = message[4:4+payload_size]
                # logger.info(f"ğŸ“‹ [PROTO] v3: type={msg_type}, payload_size={payload_size}, extracted_audio={len(audio_data)} bytes")  # ãƒ­ã‚°å‰Šæ¸›
            else:
                # Protocol v1: raw audio data
                audio_data = message

            # Server2å®Œå…¨æº–æ‹ : Connection Handlerã‚’ä½¿ç”¨ï¼ˆå…¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«å…±é€šï¼‰
            if not hasattr(self, 'connection_handler'):
                from core_connection_server2 import Server2StyleConnectionHandler
                self.connection_handler = Server2StyleConnectionHandler()
                logger.info("ğŸ¯ [CONNECTION_INIT] Server2StyleConnectionHandler initialized")
                
            # Server2æº–æ‹ ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            try:
                await self.connection_handler.route_message(audio_data, self.audio_handler)
            except Exception as route_error:
                logger.error(f"ğŸš¨S2ğŸš¨ â˜…TESTâ˜… [ROUTE_ERROR] route_message failed: {route_error}")
                import traceback
                logger.error(f"ğŸš¨S2ğŸš¨ â˜…TESTâ˜… [ROUTE_ERROR] Traceback: {traceback.format_exc()}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥audio_handlerã‚’å‘¼ã³å‡ºã—
                await self.audio_handler.handle_audio_frame(audio_data)
            
            # æ³¨æ„: æ´»å‹•æ™‚é–“æ›´æ–°ã¯æ—¢ã«ãƒ¡ã‚½ãƒƒãƒ‰å†’é ­ã§å®Ÿè¡Œæ¸ˆã¿
            
        except Exception as e:
            logger.error(f"ğŸš¨ [CRITICAL_ERROR] Binary message processing failed for {self.device_id}: {e}")
            logger.error(f"ğŸš¨ [CRITICAL_ERROR] Message details: len={len(message)}, protocol_v={self.protocol_version}")
            logger.error(f"ğŸš¨ [CRITICAL_ERROR] Message hex: {message.hex() if len(message) <= 100 else message[:100].hex()}")
            import traceback
            logger.error(f"ğŸš¨ [CRITICAL_ERROR] Full traceback: {traceback.format_exc()}")
            # Continue processing despite error to avoid connection drop
            raise  # Re-raise to trigger WebSocket disconnect investigation

    async def handle_hello_message(self, msg_json: Dict[str, Any]):
        """Handle ESP32 hello message"""
        logger.info(f"Received hello from {self.device_id}")
        
        # Store client audio parameters
        audio_params = msg_json.get("audio_params")
        if audio_params:
            self.audio_format = audio_params.get("format", "opus")
            self.welcome_msg["audio_params"] = audio_params
            logger.info(f"Client audio format: {self.audio_format}")
            
        # Store client features  
        features = msg_json.get("features")
        if features:
            self.features = features
            logger.info(f"Client features: {features}")
            
        # Send welcome response
        await self.websocket.send_str(json.dumps(self.welcome_msg))
        logger.info(f"âœ… [HELLO_RESPONSE] Sent welcome message to {self.device_id}: {self.welcome_msg}")
        logger.info(f"ğŸ¤ [HANDSHAKE] WebSocket handshake completed successfully for {self.device_id}")
        
        # Server2æº–æ‹ : ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–ã‚¿ã‚¹ã‚¯èµ·å‹•
        self.timeout_task = asyncio.create_task(self._check_timeout())
        logger.info(f"Started timeout monitoring task for {self.device_id}")

    async def handle_listen_message(self, msg_json: Dict[str, Any]):
        """Handle listen state changes"""
        state = msg_json.get("state")
        mode = msg_json.get("mode")
        
        if state == "start":
            # 3) ã€Œlisten:startã€ã‚‚ç„¡è¦–ï¼ˆTTSä¸­/ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ï¼‰
            now_ms = time.time() * 1000
            is_ai_speaking = hasattr(self, 'audio_handler') and getattr(self.audio_handler, 'client_is_speaking', False)
            is_cooldown = hasattr(self, 'audio_handler') and now_ms < getattr(self.audio_handler, 'tts_cooldown_until', 0)
            
            if is_ai_speaking or is_cooldown:
                if not hasattr(self, '_ignored_listen_count'):
                    self._ignored_listen_count = 0
                self._ignored_listen_count += 1
                
                block_reason = "AIç™ºè©±ä¸­" if is_ai_speaking else f"ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­"
                logger.info(f"ğŸ¤ [LISTEN_IGNORE] {block_reason}ã®listen:startç„¡è¦– (è¨ˆ{self._ignored_listen_count}å›)")
                return  # listen:start ã‚’ç„¡è¦–
            
            # Server2æº–æ‹ : listen startæ™‚ã®å®Œå…¨ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
            logger.info(f"ğŸ§¹ [LISTEN_START_CLEAR] Listené–‹å§‹: ãƒãƒƒãƒ•ã‚¡å®Œå…¨ã‚¯ãƒªã‚¢å®Ÿè¡Œ")
            if hasattr(self, 'audio_handler'):
                # ASRãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
                if hasattr(self.audio_handler, 'audio_frames'):
                    cleared_frames = len(self.audio_handler.audio_frames)
                    self.audio_handler.audio_frames.clear()
                    if cleared_frames > 0:
                        logger.info(f"ğŸ§¹ [LISTEN_ASR_CLEAR] Listené–‹å§‹æ™‚ASRãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢: {cleared_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                
                # VADçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
                if hasattr(self.audio_handler, 'silence_count'):
                    self.audio_handler.silence_count = 0
                if hasattr(self.audio_handler, 'last_voice_time'):
                    self.audio_handler.last_voice_time = 0
                if hasattr(self.audio_handler, 'wake_until'):
                    self.audio_handler.wake_until = 0
                    
            logger.info(f"Client {self.device_id} started listening")
        elif state == "stop":
            logger.info(f"Client {self.device_id} stopped listening")
            
        if mode:
            logger.debug(f"Client listen mode: {mode}")


    async def process_accumulated_audio(self):
        """Process accumulated voice audio data"""
        try:
            logger.info(f"ğŸ¯ [AUDIO_START] ===== Processing accumulated audio: {len(self.audio_buffer)} bytes =====")
            
            # Convert Opus to WAV using server2 method
            logger.info(f"ğŸ” [ASR] Audio format: {self.audio_format}, buffer size: {len(self.audio_buffer)}")
            
            if self.audio_format == "opus":
                logger.info(f"ğŸ”„ [WEBSOCKET] Processing as Opus format")
                # Convert Opus to WAV using server2 method
                try:
                    import wave
                    import opuslib_next
                    
                    logger.info(f"ğŸ”„ [WEBSOCKET] Converting Opus buffer to WAV (server2 method)")
                    
                    # For debugging: save original data
                    logger.info(f"ğŸ” [OPUS_DEBUG] ===== First 20 bytes: {bytes(self.audio_buffer[:20]).hex()} =====")
                    
                    # Method 1: Try as single packet
                    try:
                        decoder = opuslib_next.Decoder(16000, 1)  # 16kHz, mono
                        pcm_data = decoder.decode(bytes(self.audio_buffer), 960)  # 60ms frame
                        logger.info(f"âœ… [WEBSOCKET] Single packet decode success: {len(pcm_data)} bytes PCM")
                    except Exception as e1:
                        logger.warning(f"âš ï¸ [WEBSOCKET] Single packet failed: {e1}")
                        
                        # Method 2: Just try as raw PCM data instead of Opus
                        logger.warning(f"âš ï¸ [WEBSOCKET] Trying as raw PCM data instead")
                        # Assume it's already PCM 16-bit mono at 16kHz
                        pcm_data = bytes(self.audio_buffer)
                        logger.info(f"âœ… [WEBSOCKET] Using raw data as PCM: {len(pcm_data)} bytes")
                    
                    # Create WAV file from PCM
                    wav_buffer = io.BytesIO()
                    with wave.open(wav_buffer, 'wb') as wav_file:
                        wav_file.setnchannels(1)  # mono
                        wav_file.setsampwidth(2)  # 16-bit
                        wav_file.setframerate(16000)  # 16kHz
                        wav_file.writeframes(pcm_data)
                    
                    wav_buffer.seek(0)
                    audio_file = wav_buffer
                    audio_file.name = "audio.wav"
                    logger.info(f"ğŸ‰ [WEBSOCKET] Converted Opus to WAV: {len(self.audio_buffer)} -> {len(pcm_data)} bytes PCM")
                    
                except Exception as e:
                    logger.error(f"âŒ [WEBSOCKET] Opus conversion failed: {e}")
                    # Fallback: Create empty WAV (better than Opus for OpenAI)
                    wav_buffer = io.BytesIO()
                    with wave.open(wav_buffer, 'wb') as wav_file:
                        wav_file.setnchannels(1)
                        wav_file.setsampwidth(2) 
                        wav_file.setframerate(16000)
                        wav_file.writeframes(b'\x00' * 1600)  # 100ms of silence
                    wav_buffer.seek(0)
                    audio_file = wav_buffer
                    audio_file.name = "audio.wav"
                    logger.info(f"âš ï¸ [WEBSOCKET] Fallback: sending silent WAV")
            else:
                # Process as PCM data (ESP32 default)
                logger.info(f"ğŸ”„ [WEBSOCKET] Processing as PCM format")
                try:
                    import wave
                    
                    # Create WAV file from raw PCM data
                    wav_buffer = io.BytesIO()
                    with wave.open(wav_buffer, 'wb') as wav_file:
                        wav_file.setnchannels(1)  # mono
                        wav_file.setsampwidth(2)  # 16-bit
                        wav_file.setframerate(16000)  # 16kHz
                        wav_file.writeframes(bytes(self.audio_buffer))
                    
                    wav_buffer.seek(0)
                    audio_file = wav_buffer
                    audio_file.name = "audio.wav"
                    logger.info(f"âœ… [WEBSOCKET] Created WAV from PCM: {len(self.audio_buffer)} bytes")
                    
                except Exception as e:
                    logger.error(f"âŒ [WEBSOCKET] PCM to WAV conversion failed: {e}")
                    # Fallback: raw data
                    audio_file = io.BytesIO(bytes(self.audio_buffer))
                    audio_file.name = "audio.wav"
            
            # Convert audio to text using ASR
            logger.info(f"ğŸ¤ [ASR_START] ===== Calling OpenAI Whisper API =====")
            transcribed_text = await self.asr_service.transcribe(audio_file)
            logger.info(f"ğŸ“ [ASR_RESULT] ===== ASR Result: '{transcribed_text}' (length: {len(transcribed_text) if transcribed_text else 0}) =====")
            
            if transcribed_text and transcribed_text.strip():
                logger.info(f"âœ… [ASR] Processing transcription: {transcribed_text}")
                await self.process_text(transcribed_text)
            else:
                logger.warning(f"âŒ [ASR] No valid result for {self.device_id}")
                
        except Exception as e:
            logger.error(f"âŒ [AUDIO_ERROR] ===== Error processing accumulated audio from {self.device_id}: {e} =====")


    async def process_text(self, text: str, rid: str = None):
        """Process text input through LLM and generate response"""
        try:
            if not rid:
                import uuid
                rid = str(uuid.uuid4())[:8]
            
            # ğŸ¯ æ¤œç´¢å¯èƒ½ãƒ­ã‚°: START_TO_CHAT
            logger.info(f"ğŸ”¥ RID[{rid}] START_TO_CHAT: '{text}' (tts_active={getattr(self, 'tts_active', False)})")

            # TTSä¸­ã¯æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’æ‹’å¦
            if hasattr(self, 'tts_active') and self.tts_active:
                logger.warning(f"ğŸ”¥ RID[{rid}] START_TO_CHAT_BLOCKED: TTSä¸­ã®ãŸã‚æ‹’å¦")
                return

            # é‡è¤‡å®Ÿè¡Œé˜²æ­¢
            if hasattr(self, '_processing_text') and self._processing_text:
                logger.warning(f"ğŸ”¥ RID[{rid}] START_TO_CHAT_DUPLICATE: æ—¢ã«å‡¦ç†ä¸­ã®ãŸã‚æ‹’å¦")
                return

            self._processing_text = True
            
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–TTS RIDã‚’ã‚»ãƒƒãƒˆï¼ˆå¾Œã§Abortåˆ¤å®šã«ä½¿ç”¨ï¼‰
            if hasattr(self.audio_handler, 'active_tts_rid'):
                self.audio_handler.active_tts_rid = rid
            
            logger.info(f"ğŸ”¥ RID[{rid}] LLM_START: Processing '{text}'")
            self.chat_history.append({"role": "user", "content": text})

            # Check for memory-related keywords
            memory_query = None
            if "è¦šãˆã¦" in text or "è¨˜æ†¶ã—ã¦" in text:
                # Extract what to remember
                memory_to_save = text.replace("è¦šãˆã¦", "").replace("è¨˜æ†¶ã—ã¦", "").strip()
                if memory_to_save:
                    success = await self.memory_service.save_memory(self.device_id, memory_to_save)
                    if success:
                        await self.send_text_response("ã¯ã„ã€è¦šãˆã¾ã—ãŸã€‚")
                    else:
                        await self.send_text_response("ã™ã¿ã¾ã›ã‚“ã€è¨˜æ†¶ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    return
            elif "è¦šãˆã¦ã‚‹" in text or "ä½•ãŒå¥½ã" in text or "èª•ç”Ÿæ—¥ã¯ã„ã¤" in text:
                memory_query = text

            # Prepare messages for LLM
            llm_messages = list(self.chat_history)
            if memory_query:
                retrieved_memory = await self.memory_service.query_memory(self.device_id, memory_query)
                if retrieved_memory:
                    llm_messages.insert(0, {"role": "system", "content": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶: {retrieved_memory}"})
                    logger.info(f"Retrieved memory for LLM: {retrieved_memory[:50]}...")

            # Generate LLM response (server2 style - no extra keepalive)
            llm_response = await self.llm_service.chat_completion(llm_messages)
            
            if llm_response and llm_response.strip():
                logger.info(f"ğŸ”¥ RID[{rid}] LLM_RESULT: '{llm_response}'")
                self.chat_history.append({"role": "assistant", "content": llm_response})
                
                # Send STT message to display user input (server2 style)
                await self.send_stt_message(text)
                
                # Generate and send audio response
                logger.info(f"ğŸ”¥ RID[{rid}] TTS_START: Starting audio generation")
                await self.send_audio_response(llm_response, rid)
            else:
                logger.warning(f"ğŸ”¥ RID[{rid}] LLM_NO_RESPONSE: No response from LLM")
                
        except Exception as e:
            logger.error(f"Error processing text from {self.device_id}: {e}")
        finally:
            self._processing_text = False

    async def handle_abort_message(self, rid: str, source: str = "unknown"):
        """Server2ã®handleAbortMessageç›¸å½“å‡¦ç† - RIDè¿½è·¡å¯¾å¿œ"""
        try:
            logger.warning(f"ğŸ”¥ RID[{rid}] HANDLE_ABORT_MESSAGE: source={source}, active_tts_rid={getattr(self.audio_handler, 'active_tts_rid', 'None')}")
            
            # TTSåœæ­¢çŠ¶æ…‹è¨­å®š
            self.tts_active = False
            self._processing_text = False
            
            # Server2æº–æ‹ : Abortæ™‚ã‚‚ãƒã‚¤ã‚¯åˆ¶å¾¡ãƒªã‚»ãƒƒãƒˆ
            if hasattr(self, 'audio_handler'):
                self.audio_handler.client_is_speaking = False
                logger.info(f"ğŸ¤ [MIC_CONTROL] Abortæ™‚AIç™ºè©±åœæ­¢: client_is_speaking=False")
            
            # ESP32ã«TTSåœæ­¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ (server2æº–æ‹ )
            abort_message = {
                "type": "tts", 
                "state": "stop", 
                "session_id": getattr(self, 'session_id', 'unknown')
            }
            await self.websocket.send_str(json.dumps(abort_message))
            logger.info(f"ğŸ”¥ RID[{rid}] TTS_ABORT_SENT: Sent TTS stop message to ESP32")
            
            # Abortå¾Œã®éŒ²éŸ³å†é–‹åˆ¶å¾¡ï¼ˆé‡è¦ï¼ï¼‰
            mic_on_message = {
                "type": "audio_control", 
                "action": "mic_on", 
                "reason": "abort_recovery"
            }
            listen_start_message = {
                "type": "listen", 
                "state": "start", 
                "mode": "continuous"
            }
            try:
                await self.websocket.send_str(json.dumps(mic_on_message))
                await self.websocket.send_str(json.dumps(listen_start_message))
                logger.info(f"ğŸ”¥ RID[{rid}] ABORT_RECOVERY: ãƒã‚¤ã‚¯ON+éŒ²éŸ³å†é–‹æŒ‡ç¤ºé€ä¿¡å®Œäº†")
            except Exception as e:
                logger.warning(f"ğŸ”¥ RID[{rid}] ABORT_RECOVERY_FAILED: {e}")
            
            # éŸ³å£°å‡¦ç†çŠ¶æ…‹ã‚¯ãƒªã‚¢
            if hasattr(self.audio_handler, 'asr_audio'):
                self.audio_handler.asr_audio.clear()
            if hasattr(self.audio_handler, 'is_processing'):
                logger.warning(f"ğŸ”¥ RID[{rid}] IS_PROCESSING_ABORT: Setting is_processing=False")
                self.audio_handler.is_processing = False
                
            logger.info(f"ğŸ”¥ RID[{rid}] HANDLE_ABORT_MESSAGE_END: TTS interruption handled")
            
        except Exception as e:
            logger.error(f"ğŸ”¥ RID[{rid}] HANDLE_ABORT_MESSAGE_ERROR: {e}")

    async def handle_barge_in_abort(self):
        """Server2ã®handleAbortMessageç›¸å½“å‡¦ç†"""
        try:
            # å‘¼ã³å‡ºã—å…ƒã‚’è©³ç´°è¿½è·¡
            import traceback
            full_stack = traceback.format_stack()
            caller_details = []
            for i, frame in enumerate(full_stack[-4:-1]):
                caller_details.append(f"Level{i}: {frame.strip()}")
            
            logger.warning("ğŸš¨ [BARGE_IN_ABORT] Handling TTS interruption - server2 style")
            logger.warning(f"ğŸ” [ABORT_CALL_STACK] {' | '.join(caller_details)}")
            
            # TTSåœæ­¢çŠ¶æ…‹è¨­å®š
            self.tts_active = False
            self._processing_text = False
            
            # ESP32ã«TTSåœæ­¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ (server2æº–æ‹ )
            abort_message = {
                "type": "tts", 
                "state": "stop", 
                "session_id": getattr(self, 'session_id', 'unknown')
            }
            await self.websocket.send_str(json.dumps(abort_message))
            logger.info("ğŸ“± [TTS_ABORT] Sent TTS stop message to ESP32")
            
            # éŸ³å£°å‡¦ç†çŠ¶æ…‹ã‚¯ãƒªã‚¢
            if hasattr(self.audio_handler, 'asr_audio'):
                self.audio_handler.asr_audio.clear()
            if hasattr(self.audio_handler, 'is_processing'):
                logger.warning(f"ğŸš¨ [IS_PROCESSING_ABORT] Setting is_processing=False in handle_barge_in_abort")
                self.audio_handler.is_processing = False
                
            logger.info("âœ… [BARGE_IN_ABORT] TTS interruption handled successfully")
            
        except Exception as e:
            logger.error(f"âŒ [BARGE_IN_ABORT] Error handling TTS interruption: {e}")

    async def send_stt_message(self, text: str):
        """Send STT message to display user input (server2 style)"""
        try:
            # Enhanced connection check
            if self.websocket.closed or getattr(self.websocket, '_writer', None) is None:
                logger.warning(f"âš ï¸ [WEBSOCKET] Connection closed/invalid, cannot send STT to {self.device_id}")
                return
                
            # Send STT message (server2 style) - ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¥èª­ç‚¹ãƒ»çµµæ–‡å­—é™¤å»
            cleaned_text = self._clean_text_for_display(text)
            stt_message = {"type": "stt", "text": cleaned_text, "session_id": self.session_id}
            await self.websocket.send_str(json.dumps(stt_message))
            logger.info(f"ğŸŸ¢XIAOZHI_STT_SENTğŸŸ¢ ğŸ“± [STT] Sent user text to display: '{text}'")
        except Exception as e:
            logger.error(f"ğŸ”´XIAOZHI_STT_ERRORğŸ”´ Error sending STT message to {self.device_id}: {e}")
    
    def _clean_text_for_display(self, text: str) -> str:
        """Server2æº–æ‹ : ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¥èª­ç‚¹ãƒ»çµµæ–‡å­—ã‚’é™¤å»"""
        if not text:
            return text
        
        # åŸºæœ¬çš„ãªå¥èª­ç‚¹ãƒ»è¨˜å·é™¤å»
        punctuation_chars = "ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šï¼ˆï¼‰ã€ã€‘ã€Œã€ã€ã€ã€ˆã€‰ã€Šã€‹,.!?;:()[]<>{}"
        cleaned = text
        
        # å…ˆé ­ãƒ»æœ«å°¾ã®å¥èª­ç‚¹ãƒ»ç©ºç™½é™¤å»
        start = 0
        while start < len(cleaned) and (cleaned[start].isspace() or cleaned[start] in punctuation_chars):
            start += 1
            
        end = len(cleaned) - 1
        while end >= start and (cleaned[end].isspace() or cleaned[end] in punctuation_chars):
            end -= 1
            
        return cleaned[start:end + 1] if start <= end else text

    async def send_audio_response(self, text: str, rid: str = None):
        """Generate and send audio response"""
        try:
            if not rid:
                import uuid
                rid = str(uuid.uuid4())[:8]
            
            # ğŸ¯ æ¤œç´¢å¯èƒ½ãƒ­ã‚°: TTSé–‹å§‹
            logger.info(f"ğŸ”¥ RID[{rid}] TTS_GENERATION_START: '{text[:50]}...'")
            
            # ä¸¦è¡ŒTTSæ¤œçŸ¥
            if hasattr(self, 'tts_active') and self.tts_active:
                logger.warning(f"ğŸ”¥ RID[{rid}] HANDLE_ABORT_MESSAGE: ä¸¦è¡ŒTTSæ¤œçŸ¥ - å‰ã®TTSã‚’ä¸­æ–­")
                await self.handle_abort_message(rid, "parallel_tts")
            
            # ğŸ”‡ CRITICAL: TTSç”Ÿæˆå‰ã«å³åº§ã«ãƒã‚¤ã‚¯ã‚ªãƒ•ï¼ˆã‚¨ã‚³ãƒ¼äºˆé˜²ï¼‰
            self.client_is_speaking = True
            if hasattr(self, 'audio_handler'):
                self.audio_handler.client_is_speaking = True  # æœ€å„ªå…ˆã§ãƒã‚¤ã‚¯ã‚ªãƒ•
                
                # Server2æº–æ‹ : TTSé–‹å§‹ä¿è­·æœŸé–“è¨­å®šï¼ˆ1200msï¼‰
                tts_lock_ms = 1200
                self.audio_handler.speak_lock_until = time.time() * 1000 + tts_lock_ms
                logger.info(f"ğŸ›¡ï¸ [TTS_PROTECTION] TTSé–‹å§‹ä¿è­·æœŸé–“è¨­å®š: {tts_lock_ms}ms")
                
                # Server2æº–æ‹ : ç«¯æœ«ã«ãƒã‚¤ã‚¯ã‚ªãƒ•æŒ‡ç¤ºï¼ˆãƒ•ãƒ«ãƒ‡ãƒ¥ãƒ—ãƒ¬ãƒƒã‚¯ã‚¹è¡çªé˜²æ­¢ï¼‰
                mic_control_message = {
                    "type": "audio_control", 
                    "action": "mic_off", 
                    "reason": "tts_speaking"
                }
                try:
                    await self.websocket.send(json.dumps(mic_control_message))
                    logger.info(f"ğŸ“¡ [DEVICE_CONTROL] ç«¯æœ«ã«ãƒã‚¤ã‚¯ã‚ªãƒ•æŒ‡ç¤ºé€ä¿¡: {mic_control_message}")
                except Exception as e:
                    logger.warning(f"ğŸ“¡ [DEVICE_CONTROL] ãƒã‚¤ã‚¯ã‚ªãƒ•æŒ‡ç¤ºé€ä¿¡å¤±æ•—: {e}")
                
                # TTSé–‹å§‹æ™‚ã«éŒ²éŸ³ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢ï¼ˆæºœã¾ã£ãŸãƒ•ãƒ¬ãƒ¼ãƒ ä¸€æ–‰å‡¦ç†é˜²æ­¢ï¼‰
                if hasattr(self.audio_handler, 'audio_frames'):
                    cleared_frames = len(self.audio_handler.audio_frames)
                    self.audio_handler.audio_frames.clear()
                    if cleared_frames > 0:
                        logger.info(f"ğŸ—‘ï¸ [BUFFER_CLEAR] TTSé–‹å§‹æ™‚ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢: {cleared_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ç ´æ£„")
                
                logger.info(f"ğŸ¯ [CRITICAL_TEST] TTSé–‹å§‹: AIç™ºè¨€ãƒ•ãƒ©ã‚°ON - ã‚¨ã‚³ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯é–‹å§‹")
                
                # Server2æº–æ‹ : ç«¯æœ«ã«TTSé–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆé‡è¦ï¼ï¼‰
                tts_start_message = {
                    "type": "tts", 
                    "state": "start", 
                    "session_id": getattr(self, 'session_id', 'default')
                }
                await self.websocket.send(json.dumps(tts_start_message))
                logger.info(f"ğŸ“¡ [DEVICE_CONTROL] ç«¯æœ«ã«TTSé–‹å§‹æŒ‡ç¤ºé€ä¿¡: {tts_start_message}")
                
                self.audio_handler.tts_in_progress = True
                # TTSé€ä¿¡ä¸­ã¯ is_processing ã‚’å¼·åˆ¶ç¶­æŒ
                self.audio_handler.is_processing = True
                handler_id = id(self.audio_handler)
                logger.info(f"ğŸ¤ [MIC_CONTROL] AIç™ºè©±é–‹å§‹: client_is_speaking=True (ã‚¨ã‚³ãƒ¼é˜²æ­¢), handler_id={handler_id}")
                logger.info(f"ğŸ›¡ï¸ [TTS_PROTECTION] Set is_processing=True for TTS protection")
            
            # Check if websocket is still open (server2 style)
            # Enhanced connection validation
            if self.websocket.closed or getattr(self.websocket, '_writer', None) is None:
                logger.warning(f"âš ï¸ [WEBSOCKET] Connection closed/invalid, cannot send audio to {self.device_id}")
                return
            
            # Additional check: ensure websocket is still connected
            if not hasattr(self, 'websocket') or not self.websocket:
                logger.error(f"âŒ [WEBSOCKET] WebSocket not connected: websocket={getattr(self, 'websocket', None)}")
                return
            
            # Generate audio using TTS
            logger.info(f"ğŸ”Š [TTS_START] ===== Generating TTS for: '{text}' =====")
            
            # Send TTS start message (server2 style)
            try:
                tts_start_msg = {
                    "type": "tts", 
                    "state": "start", 
                    "session_id": self.session_id
                }
                await self.websocket.send_str(json.dumps(tts_start_msg))
                logger.info(f"ğŸ“¢ [TTS] Sent TTS start message")
                
                # ãƒãƒ³ãƒ‰ã‚·ã‚§ã‚¤ã‚¯å¾…ã¡: ESP32ã®éŸ³å£°å—ä¿¡æº–å‚™å®Œäº†ã¾ã§å¾…æ©Ÿ
                logger.info(f"â³ [HANDSHAKE] Waiting 500ms for ESP32 audio readiness")
                await asyncio.sleep(0.5)  # 500mså¾…æ©Ÿ
            except Exception as status_error:
                logger.warning(f"âš ï¸ [TTS] Failed to send TTS start: {status_error}")
                return
            
            # Send sentence_start message with AI text (server2 critical addition)
            try:
                sentence_msg = {
                    "type": "tts",
                    "state": "sentence_start", 
                    "text": text,
                    "session_id": self.session_id
                }
                await self.websocket.send_str(json.dumps(sentence_msg))
                logger.info(f"ğŸŸ¢XIAOZHI_TTS_DISPLAY_SENTğŸŸ¢ ğŸ“± [TTS_DISPLAY] Sent AI text to display: '{text}'")
            except Exception as sentence_error:
                logger.error(f"ğŸ”´XIAOZHI_TTS_DISPLAY_ERRORğŸ”´ âš ï¸ [TTS] Failed to send sentence_start: {sentence_error}")
                return
            
            # Server2æº–æ‹ : stop_eventãƒã‚§ãƒƒã‚¯å‰Šé™¤ï¼ˆTTSä¸­æ–­ãªã—ï¼‰
            
            # TTSå‡¦ç†å‰ã®æ¥ç¶šçŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            logger.info(f"ğŸ” [CONNECTION_CHECK] Before TTS generation: closed={self.websocket.closed}")
            
            # TTSç”Ÿæˆä¸­ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼šæ´»å‹•çŠ¶æ…‹æ›´æ–°
            self.last_activity_time = time.time()
            
            # Generate TTS audio (server2 style - individual frames)
            opus_frames_list = await self.tts_service.generate_speech(text)
            logger.info(f"ğŸ¶ [TTS_RESULT] ===== TTS generated: {len(opus_frames_list) if opus_frames_list else 0} individual Opus frames =====")
            
            # TTSå‡¦ç†å¾Œã®æ´»å‹•çŠ¶æ…‹æ›´æ–°ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–
            self.last_activity_time = time.time()
            logger.info(f"ğŸ” [CONNECTION_CHECK] After TTS generation: closed={self.websocket.closed}")
            
            # Server2å®Œå…¨ç§»æ¤: sendAudioHandle.py line 36-45 ç›´æ¥ç§»æ¤
            if opus_frames_list:
                try:
                    # é€ä¿¡ç›´å‰ã®æœ€çµ‚æ¥ç¶šç¢ºèª
                    if self.websocket.closed:
                        logger.error(f"ğŸš¨ [CONNECTION_ERROR] WebSocket already closed before audio send")
                        return
                    
                    # Server2æº–æ‹ : audios = å…¨ãƒ•ãƒ¬ãƒ¼ãƒ çµåˆbytes
                    audios = b''.join(opus_frames_list)
                    total_frames = len(opus_frames_list)
                    
                    # ESP32æº–æ‹ : BinaryProtocol3ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 
                    import struct
                    type_field = 0  # ESP32æœŸå¾…å€¤ï¼štype=0
                    reserved = 0    # ESP32å¿…é ˆï¼šreserved=0
                    payload_size = len(audios)
                    header = struct.pack('>BBH', type_field, reserved, payload_size)  # type(1) + reserved(1) + size(2) big-endian
                    v3_data = header + audios
                    
                    logger.info(f"ğŸµ [V3_PROTOCOL] BinaryProtocol3: type={type_field}, size={payload_size}, total={len(v3_data)} bytes")
                    logger.info(f"ğŸ” [CONNECTION_CHECK] Just before send_bytes: closed={self.websocket.closed}")
                    
                    if hasattr(self, 'websocket') and self.websocket and not self.websocket.closed:
                        # ESP32ã®OpusDecoderå¯¾å¿œ: å€‹åˆ¥ãƒ•ãƒ¬ãƒ¼ãƒ é€ä¿¡ (server2æº–æ‹ )
                        frame_count = len(opus_frames_list)
                        logger.info(f"ğŸµ [INDIVIDUAL_FRAMES] Sending {frame_count} individual Opus frames")
                        
                        # ãƒ‡ãƒãƒƒã‚°ï¼šæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ è©³ç´°è§£æ
                        if frame_count > 0:
                            first_frame = opus_frames_list[0]
                            logger.info(f"ğŸ”¬ [OPUS_DEBUG] First frame: size={len(first_frame)}bytes, hex_header={first_frame[:8].hex() if len(first_frame)>=8 else first_frame.hex()}")
                        
                        for i, opus_frame in enumerate(opus_frames_list):
                            # æ¥µå°ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆéŸ³è³ªåŠ£åŒ–ã®åŸå› ï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
                            if len(opus_frame) < 10:
                                logger.warning(f"ğŸš¨ [FRAME_SKIP] Skipping tiny frame {i+1}: {len(opus_frame)}bytes")
                                continue
                                
                            # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«å€‹åˆ¥ã®BinaryProtocol3ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
                            frame_header = struct.pack('>BBH', 0, 0, len(opus_frame))  # type=0, reserved=0, size
                            frame_data = frame_header + opus_frame
                            
                            # TTSé€ä¿¡ä¸­ã®ä¸­æ–­æ¤œçŸ¥
                            if i % 50 == 0:  # 50ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
                                logger.info(f"ğŸµ [FRAME_PROGRESS] Frame {i+1}/{frame_count}: opus={len(opus_frame)}bytes, connection_ok={not self.websocket.closed}")
                                
                            # TTSä¸­æ–­è¦å› ãƒã‚§ãƒƒã‚¯
                            if hasattr(self, '_processing_text') and not self._processing_text:
                                logger.warning(f"ğŸš¨ [TTS_INTERRUPT] _processing_text became False during TTS at frame {i+1}")
                            if hasattr(self.audio_handler, 'is_processing') and not self.audio_handler.is_processing:
                                logger.warning(f"ğŸš¨ [TTS_INTERRUPT] audio_handler.is_processing became False during TTS at frame {i+1}")
                                # TTSé€ä¿¡ä¸­ã¯å¼·åˆ¶çš„ã« is_processing ã‚’ç¶­æŒ
                                self.audio_handler.is_processing = True
                                logger.warning(f"ğŸ›¡ï¸ [TTS_PROTECTION] Forcing is_processing=True during TTS frame {i+1}")
                            
                            # ãƒ­ã‚°å‰Šæ¸›ï¼š10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã¾ãŸã¯æœ€åˆ/æœ€å¾Œã®ã¿  
                            elif i == 0 or i == frame_count-1 or (i+1) % 10 == 0:
                                logger.info(f"ğŸµ [FRAME_SEND] Frame {i+1}/{frame_count}: opus={len(opus_frame)}bytes")
                            
                            await self.websocket.send_bytes(frame_data)
                            await asyncio.sleep(0.010)  # 10ms delay - éŸ³è³ªã¨TLSè² è·ã®ãƒãƒ©ãƒ³ã‚¹
                            
                            # TLSæ¥ç¶šçŠ¶æ…‹è©³ç´°ãƒã‚§ãƒƒã‚¯
                            if self.websocket.closed:
                                logger.error(f"ğŸš¨ [TLS_ERROR] WebSocket closed during frame {i+1}, close_code={getattr(self.websocket, 'close_code', 'None')}")
                            elif getattr(self.websocket, '_writer', None) is None:
                                logger.error(f"ğŸš¨ [TLS_ERROR] Writer lost during frame {i+1}")
                                break
                            
                            if self.websocket.closed:
                                logger.error(f"ğŸš¨ [FRAME_SEND] Connection closed after frame {i+1}, stopping transmission")
                                break
                                
                        if not self.websocket.closed:
                            logger.info(f"âœ… [INDIVIDUAL_FRAMES] All {frame_count} frames sent successfully")
                    else:
                        logger.error(f"âŒ [V3_PROTOCOL] WebSocket disconnected before send")
                    
                    logger.info(f"ğŸ”µXIAOZHI_AUDIO_SENTğŸ”µ â€»ã“ã“ã‚’é€ã£ã¦ver2_AUDIOâ€» ğŸµ [AUDIO_SENT] ===== Sent {total_frames} Opus frames to {self.device_id} ({len(audios)} total bytes) =====")
                    logger.info(f"ğŸ” [DEBUG_SEND] WebSocket state after audio send: closed={self.websocket.closed}")

                    # Send TTS stop message with cooldown info (server2 style + å›ã‚Šè¾¼ã¿é˜²æ­¢)
                    tts_stop_msg = {"type": "tts", "state": "stop", "session_id": self.session_id, "cooldown_ms": 1200}  # æ®‹éŸ¿ã‚‚å«ã‚ãŸå®Œå…¨ã‚¨ã‚³ãƒ¼é™¤å»ã®ãŸã‚1200msã«å»¶é•·
                    logger.info(f"ğŸ” [DEBUG_SEND] About to send TTS stop message: {tts_stop_msg}")
                    await self.websocket.send_str(json.dumps(tts_stop_msg))
                    logger.info(f"ğŸŸ¡XIAOZHI_TTS_STOPğŸŸ¡ â€»ã“ã“ã‚’é€ã£ã¦ver2_TTS_STOPâ€» ğŸ“¢ [TTS] Sent TTS stop message with cooldown=1200ms")
                    logger.info(f"ğŸ” [DEBUG_SEND] WebSocket state after TTS stop: closed={self.websocket.closed}")
                    
                    # Server2æº–æ‹ : TTSå®Œäº†å¾Œã®æ¥ç¶šåˆ¶å¾¡
                    if self.close_after_chat:
                        logger.info(f"ğŸ”´XIAOZHI_CLOSE_AFTER_CHATğŸ”´ Closing connection after chat completion for {self.device_id}")
                        await self.websocket.close()
                        return
                    else:
                        logger.info(f"ğŸ”µXIAOZHI_CONTINUE_CONNECTIONğŸ”µ Maintaining connection after TTS completion for {self.device_id}")
                        logger.info(f"ğŸ” [DEBUG_SEND] WebSocket final state: closed={self.websocket.closed}")

                except Exception as send_error:
                    logger.error(f"âŒ [WEBSOCKET] Audio send failed to {self.device_id}: {send_error}")
                    logger.error(f"ğŸ” [DEBUG_SEND] WebSocket state after error: closed={self.websocket.closed}")
            else:
                logger.warning(f"Failed to generate audio for {self.device_id}")
                
        except Exception as e:
            logger.error(f"Error sending audio response to {self.device_id}: {e}")
        finally:
            # A. ãƒ•ãƒ©ã‚°OFFã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³å¾Œã«ä¸€æœ¬åŒ–
            # â˜…é‡è¦â˜… TTSçµ‚äº†ç›´å¾Œã«ã¯ãƒ•ãƒ©ã‚°OFFã—ãªã„ï¼ˆWebSocketå…¥å£ã‚¬ãƒ¼ãƒ‰ç¶­æŒï¼‰
            
            async def delayed_flag_off():
                try:
                    cooldown_ms = 1200  # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡æ‘˜ã®é€šã‚Š
                    cooldown_until = time.time() * 1000 + cooldown_ms
                    
                    # TTSçµ‚äº†ç›´å¾Œã«ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“è¨­å®šï¼ˆâ˜…ãƒ•ãƒ©ã‚°ã¯ç¶­æŒâ˜…ï¼‰
                    if hasattr(self, 'audio_handler'):
                        self.audio_handler.tts_cooldown_until = cooldown_until
                        
                        # Server2æº–æ‹ : TTSçµ‚äº†æ™‚ã®å®Œå…¨ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢ï¼ˆé‡è¦ï¼‰
                        logger.info(f"ğŸ§¹ [BUFFER_CLEAR_TTS_END] TTSçµ‚äº†æ™‚ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢é–‹å§‹")
                        
                        # 1. ASRéŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ˜ã‘ã®æµå…¥é˜²æ­¢ï¼‰
                        if hasattr(self.audio_handler, 'audio_frames'):
                            cleared_frames = len(self.audio_handler.audio_frames)
                            self.audio_handler.audio_frames.clear()
                            logger.info(f"ğŸ§¹ [ASR_BUFFER_CLEAR] ASRãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢: {cleared_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                        
                        # 2. VADçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆï¼ˆserver2ã®reset_vad_statesæº–æ‹ ï¼‰
                        if hasattr(self.audio_handler, 'silence_count'):
                            self.audio_handler.silence_count = 0
                        if hasattr(self.audio_handler, 'last_voice_time'):
                            self.audio_handler.last_voice_time = 0
                        if hasattr(self.audio_handler, 'wake_until'):
                            self.audio_handler.wake_until = 0
                        logger.info(f"ğŸ§¹ [VAD_RESET] VADçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆå®Œäº†")
                        
                        # 3. RMSã‚¢ã‚­ãƒ¥ãƒ ãƒ¬ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
                        if hasattr(self.audio_handler, '_rms_buffer'):
                            self.audio_handler._rms_buffer = []
                        logger.info(f"ğŸ§¹ [RMS_RESET] RMSãƒãƒƒãƒ•ã‚¡ãƒªã‚»ãƒƒãƒˆå®Œäº†")
                    
                    logger.info(f"ğŸ¯ [CRITICAL_TEST] TTSé€ä¿¡å®Œäº†: ãƒ•ãƒ©ã‚°ç¶­æŒä¸­ã€ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³{cooldown_ms}msé–‹å§‹ã€ãƒãƒƒãƒ•ã‚¡å®Œå…¨ã‚¯ãƒªã‚¢")
                    
                    # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­ã¯ãƒ•ãƒ©ã‚°ç¶­æŒï¼ˆWebSocketå…¥å£ã‚¬ãƒ¼ãƒ‰ç¶­æŒï¼‰
                    cooldown_seconds = cooldown_ms / 1000.0
                    await asyncio.sleep(cooldown_seconds)
                    
                    # â˜…ã“ã“ã§åˆã‚ã¦ãƒ•ãƒ©ã‚°OFFâ˜…ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æº€äº†å¾Œï¼‰
                    self.client_is_speaking = False
                    if hasattr(self, 'audio_handler'):
                        self.audio_handler.client_is_speaking = False  # AIç™ºè©±ç¢ºå®Ÿçµ‚äº†
                        
                        # Server2æº–æ‹ : ç«¯æœ«ã«TTSçµ‚äº† + ãƒã‚¤ã‚¯ã‚ªãƒ³æŒ‡ç¤ºé€ä¿¡
                        tts_stop_message = {
                            "type": "tts", 
                            "state": "stop", 
                            "session_id": getattr(self, 'session_id', 'default')
                        }
                        mic_on_message = {
                            "type": "audio_control", 
                            "action": "mic_on", 
                            "reason": "tts_finished"
                        }
                        try:
                            # 1. TTSåœæ­¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆServer2æº–æ‹ ï¼‰
                            await self.websocket.send(json.dumps(tts_stop_message))
                            
                            # 2. ãƒã‚¤ã‚¯ã‚ªãƒ³æŒ‡ç¤ºï¼ˆæ‹¡å¼µï¼‰
                            await self.websocket.send(json.dumps(mic_on_message))
                            
                            # 3. éŒ²éŸ³å†é–‹æŒ‡ç¤ºï¼ˆé‡è¦ï¼ESP32ãŒè‡ªå‹•å†é–‹ã—ãªã„å ´åˆã®ä¿é™ºï¼‰
                            listen_start_message = {
                                "type": "listen", 
                                "state": "start", 
                                "mode": "continuous"
                            }
                            await self.websocket.send(json.dumps(listen_start_message))
                            
                            logger.info(f"ğŸ“¡ [DEVICE_CONTROL] ç«¯æœ«åˆ¶å¾¡é€ä¿¡å®Œäº†: TTSåœæ­¢â†’ãƒã‚¤ã‚¯ONâ†’éŒ²éŸ³å†é–‹")
                            logger.info(f"ğŸ“¡ [DEVICE_CONTROL] Messages: {tts_stop_message}, {mic_on_message}, {listen_start_message}")
                        except Exception as e:
                            logger.warning(f"ğŸ“¡ [DEVICE_CONTROL] ç«¯æœ«åˆ¶å¾¡é€ä¿¡å¤±æ•—: {e}")
                        
                        # D. å¯è¦–åŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰- TTSåŒºé–“çµ±è¨ˆå‡ºåŠ›
                        ws_blocked = getattr(self, '_ws_block_count', 0)
                        ws_gate_total = getattr(self, 'ws_gate_drops', 0)
                        audio_blocked = getattr(self.audio_handler.handler if hasattr(self.audio_handler, 'handler') else None, 'blocked_frames', 0) if hasattr(self, 'audio_handler') else 0
                        cooldown_blocked = getattr(self.audio_handler, '_cooldown_log_count', 0) if hasattr(self, 'audio_handler') else 0
                        
                        logger.info(f"ğŸ¯ [CRITICAL_TEST] ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æº€äº†: AIç™ºè¨€ãƒ•ãƒ©ã‚°OFF - WebSocketå…¥å£ã‚¬ãƒ¼ãƒ‰è§£é™¤")
                        logger.info(f"ğŸ“Š [TTS_GUARD] WSå…¥å£blocked={ws_blocked} (ç´¯è¨ˆ={ws_gate_total}) Audioå±¤blocked={audio_blocked} CooldownæœŸé–“blocked={cooldown_blocked}")
                        
                        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒªã‚»ãƒƒãƒˆï¼ˆç´¯è¨ˆã¯ç¶­æŒï¼‰
                        if hasattr(self, '_ws_block_count'):
                            self._ws_block_count = 0
                            
                except Exception as e:
                    logger.error(f"ğŸš¨ [FLAG_OFF_ERROR] é…å»¶ãƒ•ãƒ©ã‚°OFFã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ç¢ºå®Ÿã«ãƒ•ãƒ©ã‚°OFFï¼ˆå®‰å…¨å¼ï¼‰
                    self.client_is_speaking = False
                    if hasattr(self, 'audio_handler'):
                        self.audio_handler.client_is_speaking = False
            
            # â˜…TTSçµ‚äº†ç›´å¾Œã¯ãƒ•ãƒ©ã‚°OFFã—ãªã„â˜…ï¼ˆå¾“æ¥ã®å³åº§ãƒªã‚»ãƒƒãƒˆã‚’å‰Šé™¤ï¼‰
            # å”¯ä¸€ã®ä¾‹å¤–å¯¾ç­–ã¨ã—ã¦ is_processing ã®ã¿ãƒªã‚»ãƒƒãƒˆ
            if hasattr(self, 'audio_handler'):
                self.audio_handler.tts_in_progress = False
                self.audio_handler.is_processing = False
                
            # éåŒæœŸã§ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³å¾Œãƒ•ãƒ©ã‚°OFFå®Ÿè¡Œ
            asyncio.create_task(delayed_flag_off())
            
            logger.info(f"ğŸ”¥ RID[{rid if 'rid' in locals() else 'unknown'}] TTS_COMPLETE: is_processing=False, ãƒ•ãƒ©ã‚°ç¶­æŒä¸­({1200}mså¾ŒOFF)")

    async def run(self):
        """Main connection loop - Server2 style with audio sync"""
        try:
            logger.info(f"ğŸŸ¢XIAOZHI_LOOP_STARTğŸŸ¢ ğŸš€ [WEBSOCKET_LOOP] Starting message loop for {self.device_id}")
            msg_count = 0
            connection_ended = False
            
            # è©³ç´°ãƒ‡ãƒãƒƒã‚°: WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡å®Œå…¨ãƒˆãƒ¬ãƒ¼ã‚¹
            try:
                logger.info(f"ğŸ” [DEBUG_LOOP] Starting async for loop for {self.device_id}, websocket.closed={self.websocket.closed}")
                last_msg_time = time.time()
                
                # ğŸš¨ é‡è¦: Server2æº–æ‹ ã®WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ãƒ«ãƒ¼ãƒ—
                logger.info(f"ğŸ” [LOOP_MONITOR] About to enter async for msg in self.websocket")
                async for msg in self.websocket:
                        # logger.info(f"ğŸ” [LOOP_MONITOR] Received message in async for loop")  # ãƒ­ã‚°å‰Šæ¸›
                    
                    # Server2æº–æ‹ : ESP32åˆ‡æ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®äº‹å‰æ¤œçŸ¥
                    if msg.type in (web.WSMsgType.CLOSE, web.WSMsgType.CLOSED, web.WSMsgType.ERROR):
                        logger.warning(f"ğŸŸ£XIAOZHI_ESP32_CLOSEğŸŸ£ ESP32 initiated close: type={msg.type}, code={getattr(msg, 'extra', 'None')}")
                        connection_ended = True
                        break
                    msg_count += 1
                    current_time = time.time()
                    time_since_last = current_time - last_msg_time
                    last_msg_time = current_time
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–“éš”ã‚‚ç›£è¦–
                    if time_since_last > 1.0:  # 1ç§’ä»¥ä¸Šã®é–“éš”
                        logger.info(f"ğŸ” [DEBUG_LOOP] Long gap detected: {time_since_last:.1f}s since last message")
                    
                    # logger.info(f"ğŸ” [DEBUG_LOOP] Message {msg_count}: type={msg.type}({msg.type.value}), closed={self.websocket.closed}, data_len={len(msg.data) if hasattr(msg, 'data') and msg.data else 'None'}, gap={time_since_last:.1f}s")  # ãƒ­ã‚°å‰Šæ¸›
                    
                    # ğŸš¨ å‡¦ç†å‰ã®WebSocketçŠ¶æ…‹ã‚’è¨˜éŒ²
                    # logger.info(f"ğŸ” [LOOP_MONITOR] Before message processing: websocket.closed={self.websocket.closed}")  # ãƒ­ã‚°å‰Šæ¸›
                    
                    # Server2æº–æ‹ : ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
                    if msg.type == web.WSMsgType.TEXT:
                        logger.info(f"ğŸ” [DEBUG_LOOP] Processing TEXT message: {msg.data[:100]}...")
                        await self.handle_message(msg.data)
                        logger.info(f"ğŸ” [DEBUG_LOOP] TEXT message processed, continuing loop, closed={self.websocket.closed}")
                    elif msg.type == web.WSMsgType.BINARY:
                        # logger.info(f"ğŸ” [DEBUG_LOOP] Processing BINARY message: {len(msg.data)} bytes")  # ãƒ­ã‚°å‰Šæ¸›
                        await self.handle_message(msg.data)
                        # logger.info(f"ğŸ” [DEBUG_LOOP] BINARY message processed, continuing loop, closed={self.websocket.closed}")  # ãƒ­ã‚°å‰Šæ¸›
                    else:
                        logger.warning(f"ğŸ” [DEBUG_LOOP] Unknown message type: {msg.type}({msg.type.value}), ignoring and continuing")
                    
                    # ğŸš¨ å‡¦ç†å¾Œã®WebSocketçŠ¶æ…‹ã‚’è¨˜éŒ²
                    # logger.info(f"ğŸ” [LOOP_MONITOR] After message processing: websocket.closed={self.websocket.closed}")  # ãƒ­ã‚°å‰Šæ¸›
                    
                    # ãƒ«ãƒ¼ãƒ—ç¶™ç¶šç¢ºèª
                    logger.debug(f"ğŸ” [DEBUG_LOOP] Loop iteration {msg_count} complete, about to continue async for")
                    
                # ğŸš¨ async for ãŒçµ‚äº†ã—ãŸç›´å¾Œã®è©³ç´°ãƒ­ã‚°
                logger.info(f"ğŸ” [LOOP_MONITOR] async for loop exited - investigating why")
                logger.info(f"ğŸ” [DEBUG_LOOP] async for loop ended naturally for {self.device_id}, final msg_count={msg_count}")
                logger.info(f"ğŸ” [DEBUG_LOOP] Time since last message when loop ended: {time.time() - last_msg_time:.1f}s")
                logger.info(f"ğŸ” [DEBUG_LOOP] WebSocket state: closed={self.websocket.closed}, close_code={getattr(self.websocket, 'close_code', 'None')}")
                
                # ESP32å´åˆ‡æ–­è©³ç´°èª¿æŸ»
                try:
                    # WebSocketçŠ¶æ…‹è©³ç´°ãƒ­ã‚°
                    logger.info(f"ğŸ” [DEBUG_LOOP] WebSocket exception: {self.websocket.exception()}")
                except:
                    logger.info(f"ğŸ” [DEBUG_LOOP] No WebSocket exception")
                    
            except Exception as loop_error:
                logger.error(f"ğŸ”¥XIAOZHI_ERRORğŸ”¥ âŒ [WEBSOCKET] Loop error for {self.device_id}: {loop_error}")
                connection_ended = True
                
            # éŸ³å£°é€ä¿¡å¾…æ©Ÿ: WebSocketãŒæ­£å¸¸ã§éŸ³å£°é€ä¿¡å¾…ã¡ã®å ´åˆã¯ç¶™ç¶š
            if not connection_ended and not self.websocket.closed:
                logger.info(f"ğŸµ [WEBSOCKET_LOOP] Waiting for pending audio transmissions for {self.device_id}")
                # æœ€å¤§3ç§’ã¾ã§éŸ³å£°é€ä¿¡å®Œäº†ã‚’å¾…æ©Ÿ
                wait_start = time.time()
                while not self.websocket.closed and (time.time() - wait_start) < 3.0:
                    await asyncio.sleep(0.1)
                    # å®Ÿéš›ã®éŸ³å£°é€ä¿¡å®Œäº†ãƒã‚§ãƒƒã‚¯ã¯ã“ã“ã§å®Ÿè£…å¯èƒ½
                    
            logger.info(f"ğŸ”µXIAOZHI_LOOP_COMPLETEğŸ”µ âœ… [WEBSOCKET_LOOP] Loop completed for {self.device_id} after {msg_count} messages")
            logger.info(f"ğŸ” [DEBUG_LOOP] Final WebSocket state: closed={self.websocket.closed}, close_code={getattr(self.websocket, 'close_code', 'None')}")
        except Exception as e:
            logger.error(f"âŒ [WEBSOCKET] Unhandled error in connection handler for {self.device_id}: {e}")
        finally:
            # Server2æº–æ‹ : ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–ã‚¿ã‚¹ã‚¯çµ‚äº†
            if self.timeout_task and not self.timeout_task.done():
                self.timeout_task.cancel()
                try:
                    await self.timeout_task
                except asyncio.CancelledError:
                    pass
                    
            logger.info(f"ğŸ” [DEBUG] WebSocket loop ended for {self.device_id}, entering cleanup")
            
    async def _check_timeout(self):
        """Server2æº–æ‹ : æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–"""
        try:
            while not self.stop_event.is_set():
                # æ´»å‹•æ™‚é–“åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
                if self.last_activity_time > 0.0:
                    current_time = time.time()
                    inactive_time = current_time - self.last_activity_time
                    
                    if inactive_time > self.timeout_seconds:
                        if not self.stop_event.is_set():
                            logger.info(f"ğŸ• [TIMEOUT] ESP32 connection timeout after {inactive_time:.1f}s for {self.device_id}")
                            self.stop_event.set()
                            try:
                                await self.websocket.close()
                            except Exception as close_error:
                                logger.error(f"Error closing timeout connection: {close_error}")
                        break
                        
                # 1ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
                await asyncio.sleep(1.0)
                
        except Exception as e:
            logger.error(f"Error in timeout check for {self.device_id}: {e}")
            